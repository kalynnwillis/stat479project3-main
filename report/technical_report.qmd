---
title: "Technical Report: Quantifying In-Air Receiver Movement"
author: "Eleanor Brothers, Kalynn Willis, Jasmine Peck"
date: today
format:
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  echo: true
  warning: false
  message: false
---

## Executive Summary

### Overview

NFL tracking data tells us how open a receiver is at the throw and at the catch, but it rarely answers a crucial question: *what happened while the ball was in the air?* Defenders are reacting, the ball is traveling, and receivers are fighting for position, yet most public metrics only capture two snapshots in time. This project introduces **In‑Air Separation Added (IASA)**, a play‑level measure of how much separation a targeted receiver gains or loses between the throw and the arrival of the ball, and combines it with a **Markov Lift** metric and a predictive model for final separation.

Using 2023 regular‑season tracking data from the Big Data Bowl (Weeks 1–18), we reconstruct the full separation trajectory for every targeted receiver. We define IASA as the change in receiver–defender distance during ball flight, categorize separation into four intuitive states (tight, moderate, open, wide open), and model transitions between these states as a Markov chain. On top of this, we fit a mixed‑effects model to separate receiver skill from play context and an XGBoost model that predicts separation at the catch from pre‑throw and situational features.

### Approach

Our analysis proceeds in four steps:

1. **Play‑level separation**: For each targeted play, we identify the throw and catch (or arrival) frames, compute distance to the nearest defender each frame, and define IASA as the difference between separation at the catch and at the throw.
2. **Separation dynamics**: We discretize separation into four states and estimate a league‑wide transition matrix that describes how often receivers move between states frame‑to‑frame. We then compute **Markov Lift** for each receiver: how often they “break open” from tight/moderate to open/wide‑open relative to league average.
3. **Context‑adjusted skill**: We fit a linear mixed‑effects model for IASA that includes air time, initial separation, and contextual play features as fixed effects and receiver/game effects as random effects. The receiver‑level random effects define **IASA over expected**.
4. **Predictive model**: We train an XGBoost model to predict final separation using only pre‑throw information (including \(d_{throw}\), air time, and play context), and evaluate its performance on a held‑out test set.

### Main Findings

League‑wide, receivers usually **lose separation** while the ball is in the air: the mean IASA is **−0.82 yards**, reflecting how defenders naturally close space on most throws, especially deeper passes with longer air time. Longer air time and larger initial separation are both associated with more negative IASA, consistent with regression to the mean and the extra time defenders have to recover. Despite this baseline, a subset of receivers consistently generate **positive IASA over expected**, adding separation even after accounting for route, coverage, and situational factors.

From the Markov‑chain perspective, separation states are “sticky” from frame to frame, but **breaking open** from tight or moderate coverage is still observable and varies across players. The league‑wide probability of moving from a covered state (tight/moderate) to an open state (open/wide‑open) is **1.49% per frame**, while top receivers exceed this by several percentage points. Our predictive model attains an RMSE of **1.79 yards** for final separation and confirms that initial separation and air time are the dominant predictive features, with context variables providing incremental but smaller gains.

### Implications

For front offices and coaches, this work separates **who created separation** from **who merely benefited from the call or coverage**. IASA over expected attributes in‑air movement skill to receivers after adjusting for down‑and‑distance, route concepts, coverage family, and box count. Markov Lift reframes separation as a **sequence of coverage states** and highlights which receivers are most likely to break open late in the route, a key skill in third‑down and red‑zone situations. The predictive model offers a complementary lens, identifying situations that are inherently separation‑friendly even before the ball is thrown. Together, these tools provide a framework for scouting receivers, designing route concepts, and communicating data‑driven insights in football language rather than purely statistical terms.

## 1. Introduction

### 1.1 Motivation and Problem Statement

In the NFL, separation is usually summarized at a single moment: how open a receiver is at the throw or at the catch. These snapshots are informative but incomplete. A receiver who is initially covered can win late separation at the catch point, while another may be wide open at the throw but allow a defender back into the play as the ball arrives. Traditional metrics blur these stories together, making it difficult to distinguish **route‑running craft** from **play design** and **coverage busts**.

Big Data Bowl tracking data offers a unique opportunity to quantify what happens during the flight of the ball. At 10 Hz resolution, we observe every step a receiver and the nearest defender take between the throw and the arrival. Our goal is to convert this raw positional data into interpretable, receiver‑centric metrics that:

- Quantify how much separation is typically gained or lost while the ball is in the air.
- Isolate receiver skill from contextual factors such as route type, coverage family, and air time.
- Identify which receivers are most likely to break open late in the route.

### 1.2 Football Examples

Consider two common scenarios:

- A deep go route against press coverage where the receiver initially loses at the line but stacks the defender and creates late separation just as the ball arrives.
- A shallow crosser scheme where route design generates a wide‑open window at the throw, but the defender closes quickly and contests the catch by the time the ball arrives.

Both plays may record similar separation at the catch, yet the underlying skills are very different. The first reflects **in‑air separation creation**, while the second reflects **in‑air separation loss** despite a favorable design. Our analysis focuses specifically on this in‑air phase.

### 1.3 Research Questions

We structure our analysis around four main questions:

1. **Baseline Behavior**: How much separation do NFL receivers typically gain or lose between the throw and the catch, and how does this distribution look across the league?
2. **Drivers of In‑Air Separation**: How do air time, initial separation, and contextual features (e.g., route and coverage families) influence IASA?
3. **Receiver Skill and Markov Lift**: After accounting for context, which receivers consistently add separation in the air? How often do they transition from tight/moderate coverage into open/wide‑open states relative to league baseline?
4. **Predictability**: To what extent can final separation be predicted using only pre‑throw information, and which features are most important?

## 2. Data Description

### 2.1 Data Sources

We utilize tracking and play‑level data from the **Big Data Bowl 2026** release, covering the **2023 NFL regular season (Weeks 1–18)**. The key components are:

- **Tracking data**: Frame‑level \(x, y\) positions for all players and the ball at 10 Hz.
- **Play metadata**: Play descriptions, game context (down, distance, time, score), and offense/defense identifiers.
- **Targeted receiver information**: Identifiers for the targeted receiver and event tags for the throw and the ball arrival (catch, pass breakup, or incompletion).

We conceptually split the tracking into:

- **Input segment**: Frames from the snap up to the throw.
- **Output segment**: Frames from the throw through the arrival of the ball or the end of the play.

Our focus in this report is on the **output segment**, where in‑air receiver–defender interactions occur.

```{r}
#| label: code-load-data
#| eval: false
# Exact code used to ingest weekly input/output CSVs from the Big Data Bowl.

# 00_load_data.R
# Description: Load and preprocess input and output tracking data.

library(tidyverse)
library(readr)

# --- Constants ---
# Determine DATA_DIR based on where the script is run from
if (dir.exists("data")) {
  DATA_DIR <- "data"
} else if (dir.exists("../data")) {
  DATA_DIR <- "../data"
} else {
  warning("Could not find data/ directory. Assuming 'data' but might fail.")
  DATA_DIR <- "data"
}

WEEKS <- sprintf("w%02d", 1:18) # Weeks w01 to w18

# --- Functions ---

load_week_data <- function(week) {
  input_file <- file.path(DATA_DIR, paste0("input_2023_", week, ".csv"))
  output_file <- file.path(DATA_DIR, paste0("output_2023_", week, ".csv"))

  if (!file.exists(input_file)) {
    warning(paste("Input file not found:", input_file))
    return(NULL)
  }
  if (!file.exists(output_file)) {
    warning(paste("Output file not found:", output_file))
    return(NULL)
  }

  message(paste("Loading data for", week, "..."))
  input_data <- read_csv(input_file, show_col_types = FALSE)
  output_data <- read_csv(output_file, show_col_types = FALSE)

  return(list(input = input_data, output = output_data))
}

load_tracking_data <- function(weeks = WEEKS) {
  # Loads data for multiple weeks and combines them (optional)
  # For now, returning a list keyed by week

  all_data <- list()

  for (week in weeks) {
    week_data <- load_week_data(week)
    if (!is.null(week_data)) {
      all_data[[week]] <- week_data
    }
  }

  return(all_data)
}

# --- Main Execution ---

if (sys.nframe() == 0) {
  # Check if data directory has files
  if (length(list.files(DATA_DIR, pattern = "\\.csv$")) == 0) {
    stop("No CSV files found in data/ directory. Please download the Big Data Bowl data.")
  }

  data <- load_tracking_data()
  message("Data loading complete.")
  # saveRDS(data, file.path(DATA_DIR, "loaded_data.rds"))
}
```

### 2.2 Sample Construction

Starting from all passing plays in Weeks 1–18, we construct our analysis sample as follows:

- Restrict to plays with a clearly identified **targeted receiver**, throw frame, and ball‑arrival frame.
- Remove plays where tracking is incomplete during the ball’s flight (e.g., missing frames or ambiguous timing).
- Compute, for each frame during ball flight, the distance between the targeted receiver and the **nearest defender**, and summarize this trajectory at the play level.

After these filters, our final dataset contains **14,108 passing plays**. For each play, we store:

- Separation at the throw (\(d_{throw}\)).
- Separation at the catch or arrival (\(d_{catch}\)).
- Air time (duration between throw and arrival).
- The full sequence of separation states (tight, moderate, open, wide open) during ball flight.
- Play‑level contextual variables used in our models (route/coverage families, box count, etc.).

```{r}
#| label: code-feature-engineering
#| eval: false
# Exact feature-engineering code used to construct play-level separation and trajectories.

# 01_engineer_features.R
# Description: Feature engineering for receiver movement analysis.
# Input: Raw tracking data (from 00_load_data.R)
# Output: Play-level features including separation at throw/catch.

library(tidyverse)

# --- Helpers ---

identify_targeted_receiver <- function(play_data) {
  tr <- play_data |>
    filter(player_role == "Targeted Receiver") |>
    distinct(nfl_id) |>
    pull(nfl_id)

  if (length(tr) == 0) {
    return(NA_integer_)
  } # no targeted receiver (should be rare)
  if (length(tr) > 1) {
    # if multiple, just take first for now; you can refine later
    warning("Multiple targeted receivers found in one play; taking first.")
    tr <- tr[1]
  }
  tr
}

calculate_separation <- function(receiver_loc, defenders_loc) {
  if (nrow(receiver_loc) == 0 || nrow(defenders_loc) == 0) {
    return(NA_real_)
  }
  rx <- receiver_loc$x[1]
  ry <- receiver_loc$y[1]
  dx <- defenders_loc$x
  dy <- defenders_loc$y
  min(sqrt((rx - dx)^2 + (ry - dy)^2))
}

compute_play_separation <- function(gid, pid, input_df, output_df) {
  play_in <- input_df |> filter(game_id == gid, play_id == pid)
  play_out <- output_df |> filter(game_id == gid, play_id == pid)

  if (nrow(play_in) == 0 || nrow(play_out) == 0) {
    return(NULL)
  }

  tr_id <- identify_targeted_receiver(play_in)
  if (is.na(tr_id)) {
    return(NULL)
  }

  # --- Throw frame (input data: up to throw) ---
  throw_frame <- max(play_in$frame_id, na.rm = TRUE)
  rec_throw <- play_in |> filter(nfl_id == tr_id, frame_id == throw_frame)

  # Targeted receiver name (from input CSV)
  tr_name_vec <- play_in |>
    filter(nfl_id == tr_id) |>
    distinct(player_name) |>
    pull(player_name)

  tr_name <- if (length(tr_name_vec) > 0) tr_name_vec[1] else NA_character_

  # Identify Defenders
  defs_throw <- play_in |>
    filter(player_role == "Defensive coverage", frame_id == throw_frame)

  if (nrow(defs_throw) == 0) {
    message(
      "No 'Defensive coverage' labels for game ", gid,
      ", play ", pid, "; using non-offensive players at throw_frame as defenders."
    )
    defs_throw <- play_in |>
      filter(!player_role %in% c("Targeted Receiver", "Passer", "Other Route Runner"), frame_id == throw_frame)
  }

  defender_ids <- unique(defs_throw$nfl_id)

  d_throw <- calculate_separation(rec_throw, defs_throw)

  # --- In-air frames (output data: from throw to ball arrival) ---
  rec_out <- play_out |> filter(nfl_id == tr_id)
  if (nrow(rec_out) == 0) {
    return(NULL)
  }

  first_out_frame <- min(rec_out$frame_id, na.rm = TRUE)
  catch_frame <- max(rec_out$frame_id, na.rm = TRUE)
  rec_catch <- rec_out |> filter(frame_id == catch_frame)

  defs_catch <- play_out |>
    filter(nfl_id %in% defender_ids, frame_id == catch_frame)

  d_catch <- calculate_separation(rec_catch, defs_catch)

  # Assume 10 Hz frame rate; air_time is time between first in-air frame
  # in the output and the catch frame.
  air_time <- (catch_frame - first_out_frame) * 0.1

  # --- NEW: Compute Separation Trajectory ---
  # We compute separation for EVERY frame in the output for this receiver
  # Using simple map instead of group_modify to avoid grouping issues

  frames <- unique(rec_out$frame_id)

  traj_list <- map(frames, function(f) {
    rec_loc <- rec_out |> filter(frame_id == f)
    defs <- play_out |> filter(frame_id == f, nfl_id %in% defender_ids)

    tibble(
      game_id = gid,
      play_id = pid,
      frame_id = f,
      separation = calculate_separation(rec_loc, defs)
    )
  })

  traj_df <- bind_rows(traj_list)

  list(
    play_features = tibble(
      game_id = gid,
      play_id = pid,
      targeted_id = tr_id,
      targeted_name = tr_name,
      throw_frame = throw_frame,
      catch_frame = catch_frame,
      d_throw = d_throw,
      d_catch = d_catch,
      air_time = air_time,
      ball_land_x = first(play_in$ball_land_x),
      ball_land_y = first(play_in$ball_land_y)
    ),
    trajectory = traj_df
  )
}

build_play_feature_table <- function(week_data) {
  input_df <- week_data$input
  output_df <- week_data$output

  plays <- input_df |> distinct(game_id, play_id)

  message(paste("Processing", nrow(plays), "plays..."))

  all_features <- list()
  all_trajectories <- list()

  for (i in 1:nrow(plays)) {
    p <- plays[i, ]
    res <- compute_play_separation(p$game_id, p$play_id, input_df, output_df)

    if (!is.null(res)) {
      all_features[[length(all_features) + 1]] <- res$play_features
      all_trajectories[[length(all_trajectories) + 1]] <- res$trajectory
    }

    if (i %% 100 == 0) cat(".")
  }
  cat("\n")

  features_df <- if (length(all_features) > 0) dplyr::bind_rows(all_features) else tibble()
  traj_df <- if (length(all_trajectories) > 0) dplyr::bind_rows(all_trajectories) else tibble()

  list(
    features = features_df,
    trajectories = traj_df
  )
}

# --- Main Execution (if run as script) ---

if (sys.nframe() == 0) {
  # Source helpers and loader from the same directory
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Cannot find utils_paths.R")
  }

  if (file.exists("src/00_load_data.R")) {
    source("src/00_load_data.R")
  } else if (file.exists("00_load_data.R")) {
    source("00_load_data.R")
  } else {
    stop("Cannot find 00_load_data.R")
  }

  OUT_DIR <- get_proc_dir()

  message(paste("Processing weeks:", paste(WEEKS, collapse = ", ")))

  for (week in WEEKS) {
    message(paste("--- Starting", week, "---"))
    week_data_list <- load_week_data(week)

    if (is.null(week_data_list)) {
      message(paste("Skipping", week, "- data not found."))
      next
    }

    message(paste("Building play-level feature table for", week, "..."))
    results <- build_play_feature_table(week_data_list)

    # Save Features
    feat_file <- file.path(OUT_DIR, paste0("play_features_", week, ".rds"))
    saveRDS(results$features, feat_file)

    # Save Trajectories (New!)
    traj_file <- file.path(OUT_DIR, paste0("separation_trajectories_", week, ".rds"))
    saveRDS(results$trajectories, traj_file)

    message(paste("Saved", feat_file, "and", traj_file))

    rm(week_data_list, results)
    gc()
  }
}
```

## 3. Methodology

### 3.1 In‑Air Separation Added (IASA)

Our primary play‑level metric is **In‑Air Separation Added (IASA)**, defined as:

$$
IASA = d_{catch} - d_{throw},
$$

where \(d_{throw}\) is the distance (in yards) between the targeted receiver and the nearest defender at the throw frame, and \(d_{catch}\) is the corresponding distance at the ball‑arrival frame. Positive IASA indicates that the receiver **gained separation** while the ball was in the air, whereas negative IASA indicates that the defender **closed the gap**.

Interpreting IASA:

- A receiver with \(IASA = +1.0\) yard turned a marginally contested target (\(d_{throw} = 2.5\) yards) into a more open catch point (\(d_{catch} = 3.5\) yards).
- A receiver with \(IASA = -1.5\) yards may have started open but allowed a defender to re‑enter the passing lane by the catch.

IASA is intentionally simple: it summarizes the net change in separation over the ball’s flight, while our other methods (Markov Lift and mixed‑effects modeling) provide more nuanced views.

```{r}
#| label: code-compute-iasa
#| eval: false
# Exact code used to compute IASA and join supplementary context.

# 02_compute_IASA.R
# Description: Compute In-Air Separation Added (IASA).
# Formula: IASA = d_catch - d_throw
# Interpretation:
#   Positive IASA -> Gained separation (Good for WR)
#   Negative IASA -> Lost separation (Good for DB)

library(tidyverse)

compute_iasa <- function(play_features) {
  play_features |>
    mutate(
      IASA = d_catch - d_throw,
      # Additional derived metrics
      separation_change_pct = ifelse(d_throw > 0, (d_catch - d_throw) / d_throw, NA_real_),
      is_separation_gained = IASA > 0
    )
}

if (sys.nframe() == 0) {
  # Source path helpers
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  # Determine input/output directory
  PROC_DIR <- get_proc_dir()

  # Find all feature files
  feature_files <- list.files(PROC_DIR, pattern = "play_features_w[0-9]+\\.rds", full.names = TRUE)

  if (length(feature_files) == 0) {
    stop(paste("No feature files found in", PROC_DIR, ". Run 01_engineer_features.R first."))
  }

  message(paste("Found", length(feature_files), "feature files. Loading and combining..."))

  features <- purrr::map_dfr(feature_files, readRDS)

  message(paste("Total plays loaded:", nrow(features)))

  message("Computing IASA and derived metrics...")
  analysis_df <- compute_iasa(features)

  # --- Optional: Join supplementary play-level data, if available ---
  # This adds route / coverage / EPA context from BDB2026_supplementary_data.csv
  SUPP_PATH <- NULL
  if (dir.exists("data")) {
    SUPP_PATH <- file.path("data", "BDB2026_supplementary_data.csv")
  } else if (dir.exists("../data")) {
    SUPP_PATH <- file.path("../data", "BDB2026_supplementary_data.csv")
  }

  if (!is.null(SUPP_PATH) && file.exists(SUPP_PATH)) {
    message("Joining supplementary play-level data...")

    supp <- readr::read_csv(SUPP_PATH, show_col_types = FALSE) |>
      dplyr::select(
        game_id,
        play_id,
        season,
        week,
        play_description,
        offense_formation,
        receiver_alignment,
        route_of_targeted_receiver,
        pass_result,
        pass_length,
        pass_location_type,
        play_action,
        dropback_type,
        dropback_distance,
        defenders_in_the_box,
        team_coverage_man_zone,
        team_coverage_type,
        expected_points,
        expected_points_added,
        yards_gained
      )

    # Ensure join keys have compatible types
    analysis_df <- analysis_df |>
      mutate(
        game_id = as.numeric(game_id),
        play_id = as.numeric(play_id)
      ) |>
      left_join(
        supp |>
          mutate(
            game_id = as.numeric(game_id),
            play_id = as.numeric(play_id)
          ),
        by = c("game_id", "play_id")
      )
  } else {
    message("Supplementary play-level data not found; proceeding without it.")
  }

  # Basic summary
  summary_stats <- analysis_df |>
    summarise(
      avg_IASA = mean(IASA, na.rm = TRUE),
      median_IASA = median(IASA, na.rm = TRUE),
      prop_positive = mean(IASA > 0, na.rm = TRUE),
      n_plays = n()
    )

  print(summary_stats)

  saveRDS(analysis_df, file.path(PROC_DIR, "analysis_full.rds"))
  message(paste("Saved analysis_full.rds to", PROC_DIR))
}
```

### 3.2 Separation States and Markov Lift

To study separation as a **dynamic process**, we discretize separation at each frame into four states:

- **S0 (Tight)**: \< 1 yard
- **S1 (Moderate)**: 1–3 yards
- **S2 (Open)**: 3–5 yards
- **S3 (Wide Open)**: \> 5 yards

For each targeted route, we observe a sequence of states \((S_t)_{t=1}^T\) during ball flight. We model these transitions with a first‑order **Markov chain**, estimating the transition probabilities:

$$
P(S_{t+1} = j \mid S_t = i), \quad i, j \in \{0,1,2,3\}.
$$

The league‑wide transition matrix captures how likely a receiver is to maintain or change separation from frame to frame. The diagonal elements reflect **state persistence**, while off‑diagonal elements represent gains or losses in separation.

We focus on transitions from **covered** states (S0, S1) to **open** states (S2, S3). Define:

$$
p^{\text{league}}_{\text{break}} = P(S_{t+1} \in \{2,3\} \mid S_t \in \{0,1\})
$$

as the league‑average probability of “breaking open” in a single frame. Empirically, this baseline is **1.49% per frame**.

For each receiver, we compute an analogous empirical probability \(p^{\text{player}}_{\text{break}}\) based on their frame‑level transitions. We then define **Markov Lift** as:

$$
\text{Markov Lift} = p^{\text{player}}_{\text{break}} - p^{\text{league}}_{\text{break}}.
$$

Positive Markov Lift indicates that the receiver breaks open from coverage more often than an average NFL receiver, controlling for the fact that the event is rare on any single frame. This metric is naturally expressed in percentage points (e.g., “+6.2%”).

```{r}
#| label: code-markov-lift
#| eval: false
# Exact code used to build Markov transitions and Markov Lift.

# 06_markov_separation.R
# Description: Analyze separation trajectories using Markov Chains.
# Goal: Compute transition probabilities between separation states and "Markov Lift".

library(tidyverse)

# --- Constants ---
# Define separation states (in yards)
# S0: < 1 yard (Tight)
# S1: 1-3 yards (Moderate)
# S2: 3-5 yards (Open)
# S3: > 5 yards (Wide Open)

get_state <- function(sep) {
  case_when(
    sep < 1 ~ "S0_Tight",
    sep < 3 ~ "S1_Moderate",
    sep < 5 ~ "S2_Open",
    TRUE ~ "S3_WideOpen"
  )
}

# Order of states for matrix
STATE_LEVELS <- c("S0_Tight", "S1_Moderate", "S2_Open", "S3_WideOpen")

# --- Functions ---

load_trajectories <- function(proc_dir = "processed") {
  files <- list.files(proc_dir, pattern = "separation_trajectories_w[0-9]+\\.rds", full.names = TRUE)
  if (length(files) == 0) stop("No trajectory files found.")

  message(paste("Loading", length(files), "trajectory files..."))

  map(files, readRDS) |>
    dplyr::bind_rows()
}

compute_transitions <- function(traj_df) {
  # Compute state t -> state t+1 for each play
  traj_df |>
    arrange(game_id, play_id, frame_id) |>
    group_by(game_id, play_id) |>
    mutate(
      state = get_state(separation),
      next_state = lead(state)
    ) |>
    # Drop any transitions where either side is NA
    filter(!is.na(state), !is.na(next_state)) |>
    ungroup()
}

estimate_transition_matrix <- function(transitions) {
  # Enforce consistent state ordering and keep zero-count combos
  transitions <- transitions |>
    mutate(
      state = factor(state, levels = STATE_LEVELS),
      next_state = factor(next_state, levels = STATE_LEVELS)
    )

  # Count transitions (including zero cells)
  counts <- transitions |>
    count(state, next_state, .drop = FALSE)

  # Convert to probabilities by row (current state)
  counts |>
    group_by(state) |>
    mutate(prob = ifelse(sum(n) > 0, n / sum(n), 0)) |>
    ungroup()
}

plot_transition_matrix <- function(trans_probs) {
  ggplot(trans_probs, aes(x = next_state, y = fct_rev(state), fill = prob)) +
    geom_tile() +
    geom_text(aes(label = round(prob, 2)), color = "white") +
    scale_fill_gradient(low = "navy", high = "red") +
    theme_minimal() +
    labs(
      title = "Separation State Transition Probabilities",
      subtitle = "Probability of moving from State Y to State X in next frame",
      x = "Next State",
      y = "Current State",
      fill = "Probability"
    )
}

compute_markov_lift <- function(transitions, features_df) {
  # Calculate how often a specific receiver improves their state vs league average
  # Improvement: Moving to a 'better' state index, or maintaining a good state?
  # Let's define "Positive Outcome" as ending in Open/WideOpen (S2/S3)

  # Actually, simpler metric:
  # For each transition observed for a player (Start -> End),
  # What was the PROBABILITY the league would have made that transition?
  # Or: Difference between Player's transition matrix and League matrix?

  # Metric: "Openness Lift"
  # P(End in S2/S3 | Start in S0/S1) for Player vs League

  # Filter for starts in Tight/Moderate
  relevant_starts <- c("S0_Tight", "S1_Moderate")
  good_ends <- c("S2_Open", "S3_WideOpen")

  # League Baseline
  league_rate <- transitions |>
    filter(state %in% relevant_starts) |>
    summarise(
      success_rate = mean(next_state %in% good_ends)
    ) |>
    pull(success_rate)

  message("League Baseline Success Rate (S0/S1 -> S2/S3): ", round(league_rate, 4))

  player_stats <- transitions |>
    inner_join(features_df, by = c("game_id", "play_id")) |>
    filter(state %in% relevant_starts) |>
    group_by(targeted_id) |>
    summarise(
      n_transitions = n(),
      successes = sum(next_state %in% good_ends),
      player_rate = successes / n_transitions
    ) |>
    filter(n_transitions >= 50) |> # Minimum sample size
    mutate(
      markov_lift = player_rate - league_rate
    ) |>
    arrange(desc(markov_lift))

  player_stats
}

compute_break_counts <- function(transitions, features_df, min_transitions = 50) {
  # Helper to compute per-receiver transition counts and successes for S0/S1 -> S2/S3
  relevant_starts <- c("S0_Tight", "S1_Moderate")
  good_ends <- c("S2_Open", "S3_WideOpen")

  league_rate <- transitions |>
    filter(state %in% relevant_starts) |>
    summarise(
      success_rate = mean(next_state %in% good_ends)
    ) |>
    pull(success_rate)

  player_counts <- transitions |>
    inner_join(features_df, by = c("game_id", "play_id")) |>
    filter(state %in% relevant_starts) |>
    group_by(targeted_id) |>
    summarise(
      n_transitions = n(),
      successes = sum(next_state %in% good_ends),
      .groups = "drop"
    ) |>
    filter(n_transitions >= min_transitions)

  list(
    break_df = player_counts,
    league_rate = league_rate
  )
}

fit_bayesian_markov_model <- function(break_df) {
  # Fit a hierarchical Bayesian model for break-open rates
  if (!requireNamespace("brms", quietly = TRUE)) {
    warning("Package 'brms' not installed; skipping Bayesian Markov Lift model.")
    return(NULL)
  }

  message("Fitting Bayesian Markov model for break-open rates (via brms)...")

  break_df <- break_df |>
    mutate(targeted_id = as.factor(targeted_id))

  bayes_fit <- brms::brm(
    successes | trials(n_transitions) ~ 1 + (1 | targeted_id),
    data = break_df,
    family = binomial(),
    prior = c(
      brms::prior(normal(0, 2), class = "Intercept"),
      brms::prior(exponential(1), class = "sd")
    ),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    cores = min(4, parallel::detectCores()),
    control = list(adapt_delta = 0.95),
    refresh = 0
  )

  bayes_fit
}

extract_bayesian_markov_lift <- function(bayes_model, break_df, league_rate) {
  # Extract posterior summaries for per-receiver break-open probabilities and lift
  if (is.null(bayes_model) || nrow(break_df) == 0) {
    return(NULL)
  }

  # Posterior expected probabilities for each row in break_df
  # posterior_epred returns draws on the probability scale for binomial models
  post_prob <- brms::posterior_epred(
    bayes_model,
    newdata = break_df,
    re_formula = ~ (1 | targeted_id)
  )

  # post_prob: iterations x n_players
  summaries <- t(apply(post_prob, 2, function(draws) {
    c(
      player_rate_mean  = mean(draws),
      player_rate_sd    = sd(draws),
      player_rate_lower = quantile(draws, 0.025),
      player_rate_upper = quantile(draws, 0.975),
      markov_lift_mean  = mean(draws) - league_rate,
      markov_lift_lower = quantile(draws - league_rate, 0.025),
      markov_lift_upper = quantile(draws - league_rate, 0.975)
    )
  }))

  summaries <- as_tibble(summaries)

  tibble(
    targeted_id = as.character(break_df$targeted_id),
    n_transitions = break_df$n_transitions,
    successes = break_df$successes
  ) |>
    bind_cols(summaries) |>
    arrange(desc(markov_lift_mean))
}

# --- Main Execution ---

if (sys.nframe() == 0) {
  # Source path helpers
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  PROC_DIR <- get_proc_dir()

  message("Loading trajectories...")
  traj <- load_trajectories(PROC_DIR)

  message("Computing transitions...")
  trans <- compute_transitions(traj)

  message("Estimating league transition matrix...")
  tm <- estimate_transition_matrix(trans)
  print(tm)

  # Save plot
  p <- plot_transition_matrix(tm)
  FIG_DIR <- get_fig_dir()
  ggsave(file.path(FIG_DIR, "markov_transitions.png"), p, width = 8, height = 6)

  message("Computing Markov Lift for players...")
  features_df <- readRDS(file.path(PROC_DIR, "analysis_full.rds")) |>
    select(game_id, play_id, targeted_id)
  lift <- compute_markov_lift(trans, features_df)

  # Optionally add names if targeted_name is available in analysis data
  df_names <- readRDS(file.path(PROC_DIR, "analysis_full.rds"))
  if ("targeted_name" %in% names(df_names)) {
    name_map <- df_names |>
      distinct(targeted_id, targeted_name) |>
      mutate(targeted_id = as.character(targeted_id))

    lift <- lift |>
      mutate(targeted_id = as.character(targeted_id)) |>
      left_join(name_map, by = "targeted_id") |>
      relocate(targeted_name, .before = targeted_id)
  }

  print(head(lift, 10))

  write_csv(lift, file.path(PROC_DIR, "markov_lift_rankings.csv"))
  message("Saved markov_lift_rankings.csv")

  # --- Bayesian Markov Lift (if brms is available) ---
  message("Fitting Bayesian Markov Lift model (if brms is installed)...")
  break_info <- compute_break_counts(trans, features_df, min_transitions = 50)
  bayes_markov <- fit_bayesian_markov_model(break_info$break_df)
  bayes_lift <- extract_bayesian_markov_lift(bayes_markov, break_info$break_df, break_info$league_rate)

  if (!is.null(bayes_markov) && !is.null(bayes_lift)) {
    if ("targeted_name" %in% names(df_names)) {
      name_map <- df_names |>
        distinct(targeted_id, targeted_name) |>
        mutate(targeted_id = as.character(targeted_id))

      bayes_lift <- bayes_lift |>
        mutate(targeted_id = as.character(targeted_id)) |>
        left_join(name_map, by = "targeted_id") |>
        relocate(targeted_name, .before = targeted_id)
    }

    message("Bayesian Markov Lift model fit successfully.")
    print(head(bayes_lift, 10))

    saveRDS(bayes_markov, file.path(PROC_DIR, "markov_lift_bayes_model.rds"))
    write_csv(bayes_lift, file.path(PROC_DIR, "markov_lift_rankings_bayes.csv"))
  } else {
    message("Bayesian Markov Lift model not fit; skipping Bayesian lift export.")
  }
}
```

### Predictors and Rationale

Our goal in the mixed‑effects model is to explain how much separation a receiver gains or loses while the ball is in the air. Each covariate is chosen to capture one of three ideas:

- **Opportunity for movement**: how much time and space the receiver has to change leverage mid‑route.
- **Coverage difficulty**: how constrained the receiver’s movement is by the defensive structure.
- **Route‑level context**: how much in‑air adjustment a particular route concept naturally allows.

#### Opportunity variables

These covariates describe the “canvas” on which in‑air separation can change:

- **Air Time (scaled)**: Longer throws provide more frames for defenders to close and receivers to separate. Because separation change is inherently time‑dependent, controlling for air time prevents deep throws from being treated as “better” simply because they last longer.
- **Distance at Throw (scaled)**: Starting leverage matters. A receiver who is already wide open at release should not be credited for “gaining” separation just because the defender begins far away.
- **Pass Length (scaled)**: A proxy for route depth. Deeper routes differ systematically in defender recovery behavior, ball flight, and the amount of space receivers can work with.

#### Coverage difficulty variables

These terms represent how challenging the coverage environment is for creating separation:

- **Defenders in the Box (scaled)**: Higher counts often correspond to tighter formations or heavier defensive fronts, which correlate with man coverage, press looks, or aggressive safety rotations that shape initial leverage and recovery angles.
- **Team coverage indicators (Man vs. Zone / coverage family)**: Coverage scheme determines defender responsibilities. In man coverage, separation changes primarily reflect one‑on‑one matchups; in zone, they reflect how well receivers find and exploit space between defenders.

#### Route‑level context

Routes differ substantially in how much in‑air adjustment they permit:

- **Route of Targeted Receiver**: A vertical “go” route offers more variance in in‑air separation than a shallow drag or quick out. Including route family prevents us from attributing route‑driven patterns (e.g., back‑shoulder fades, crossers vs. curls) to the receiver’s individual skill.

#### Random effects

Finally, we use random effects to respect the nested structure of the data:

- **Receiver random intercept \((1 \mid \text{targeted\_id})\)**: Captures persistent, player‑specific deviations in IASA over expected after controlling for the fixed‑effect covariates—our notion of in‑air separation skill.
- **Game random intercept \((1 \mid \text{game\_id})\)**: Accounts for shared game‑level conditions such as opponent quality, weather, and scheme tendencies that affect all plays within a game.

### 3.3 Mixed‑Effects Model for IASA over Expected

Raw IASA conflates receiver skill with **context**: longer air‑time throws, high‑leverage downs, and certain route/coverage combinations are naturally harder environments in which to gain separation. To isolate receiver skill, we fit a **linear mixed‑effects model**:

$$
IASA_{\text{play}} = \beta_0
  + \beta_1 \cdot \text{Air Time}
  + \beta_2 \cdot d_{throw}
  + \mathbf{x}_{\text{play}}^\top \boldsymbol{\beta}
  + u_{\text{receiver}}
  + u_{\text{game}}
  + \epsilon,
$$

where:

- \(\mathbf{x}_{\text{play}}\) encodes contextual fixed effects (e.g., route family, coverage family, box count, down‑and‑distance).
- \(u_{\text{receiver}}\) is a receiver‑level random effect capturing **in‑air separation skill** not explained by context.
- \(u_{\text{game}}\) is a game‑level random effect capturing shared conditions within a game (e.g., weather, opponent tendencies).
- \(\epsilon\) is residual error.

We estimate the model using standard mixed‑effects software and summarize receiver skill via **IASA over expected**, defined as the estimated receiver random effect \(u_{\text{receiver}}\). Intuitively, a receiver with \(u_{\text{receiver}} = +0.4\) tends to finish plays with roughly 0.4 yards more in‑air separation than expected, conditional on their route mix and situations; a receiver with \(u_{\text{receiver}} = -0.3\) tends to lose additional separation relative to expectation.

In our implementation, we standardize the continuous predictors (air time, \(d_{throw}\), pass length, and defenders in the box) before fitting, so the model is actually fit on scaled versions of these variables. The equation above is written in terms of the original units for interpretability, but the reported coefficients in the model summaries correspond to one‑standard‑deviation changes in each continuous predictor rather than one‑yard or one‑second changes.

To quantify uncertainty in these receiver effects, we also fit a **Bayesian analogue** of the mixed‑effects model using weakly informative priors on the fixed effects and on the receiver/game random‑effect standard deviations. This yields a posterior distribution for each receiver’s IASA over expected, from which we report posterior means and 95% credible intervals; players with few targets naturally have wider intervals, reflecting greater uncertainty in their estimated in‑air separation skill.

Model diagnostics (fitted vs. observed IASA and residual distributions) are used to assess linearity, variance assumptions, and the contribution of random effects.

```{r}
#| label: code-mixed-effects
#| eval: false
# Exact code used for mixed-effects and Bayesian IASA over expected models.

# 03_models.R
# Description: Statistical and ML modeling of IASA.
# Goal: Isolate receiver ability (random intercept) controlling for context.

library(tidyverse)
library(lme4)
library(broom.mixed) # For tidy model outputs

# --- Functions ---

fit_mixed_effects_model <- function(data) {
  # Model IASA controlling for:
  # - Air Time (longer throws allow more convergence)
  # - Initial Separation (regression to the mean)
  # - Route / coverage context and defensive structure
  # - Random Effect: Receiver ID (The metric we want)
  # - Random Effect: Game ID (Game-specific conditions/weather)

  message("Fitting Mixed-Effects Model: IASA ~ air_time_scaled + d_throw_scaled + pass_length_scaled + defenders_in_the_box_scaled +\n  team_coverage_man_zone + route_of_targeted_receiver + (1|targeted_id) + (1|game_id)...")

  m <- lmer(
    IASA ~ air_time_scaled + d_throw_scaled + pass_length_scaled + defenders_in_the_box_scaled +
      team_coverage_man_zone + route_of_targeted_receiver +
      (1 | targeted_id) + (1 | game_id),
    data = data,
    REML = FALSE
  )
  return(m)
}

extract_receiver_rankings <- function(model) {
  # Extract random intercepts for receivers (targeted_id)
  ranefs <- ranef(model)$targeted_id

  ranefs |>
    as_tibble(rownames = "nfl_id") |>
    rename(iasa_over_expected = `(Intercept)`) |>
    arrange(desc(iasa_over_expected))
}

fit_bayesian_iasa_model <- function(data) {
  # Fit a Bayesian analogue of the mixed-effects model (partial pooling over receivers/games)
  if (!requireNamespace("brms", quietly = TRUE)) {
    warning("Package 'brms' not installed; skipping Bayesian IASA model.")
    return(NULL)
  }

  message("Fitting Bayesian Mixed-Effects Model for IASA (via brms)...")

  bayes_fit <- brms::brm(
    IASA ~ air_time + d_throw + pass_length + defenders_in_the_box +
      team_coverage_man_zone + route_of_targeted_receiver +
      (1 | targeted_id) + (1 | game_id),
    data = data,
    family = gaussian(),
    prior = c(
      brms::prior(normal(0, 2), class = "Intercept"),
      brms::prior(normal(0, 1), class = "b"),
      brms::prior(exponential(1), class = "sd"),
      brms::prior(exponential(1), class = "sigma")
    ),
    iter = 4000,
    warmup = 1000,
    chains = 4,
    cores = min(4, parallel::detectCores()),
    control = list(adapt_delta = 0.95),
    refresh = 0
  )

  bayes_fit
}

extract_bayesian_receiver_rankings <- function(bayes_model) {
  # Extract posterior mean and 95% CrI for receiver random intercepts (IASA over expected)
  # NOTE: This helper is intentionally conservative; if the structure of the
  # brms object is not as expected, it returns NULL and the pipeline falls
  # back to frequentist rankings only.
  if (is.null(bayes_model)) {
    return(NULL)
  }

  # Use posterior draws for random effects; this is more robust to version
  # differences than relying on summary dimnames.
  if (!requireNamespace("posterior", quietly = TRUE)) {
    warning("Package 'posterior' not available; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  draws <- brms::as_draws_df(bayes_model)

  # Levels of the targeted receiver random effect in the model data
  if (!"targeted_id" %in% names(bayes_model$data)) {
    warning("Model data does not contain 'targeted_id'; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  receiver_ids <- unique(as.character(bayes_model$data$targeted_id))

  summary_list <- purrr::map(receiver_ids, function(rid) {
    cand_cols <- c(
      paste0("r_targeted_id[", rid, ",Intercept]"),
      paste0("r_targeted_id[", rid, ",(Intercept)]")
    )
    col_name <- cand_cols[cand_cols %in% names(draws)][1]
    if (is.na(col_name)) {
      return(NULL)
    }
    vals <- draws[[col_name]]
    tibble(
      nfl_id = rid,
      iasa_over_expected_mean = mean(vals),
      iasa_over_expected_sd = sd(vals),
      iasa_over_expected_lower = quantile(vals, 0.025),
      iasa_over_expected_upper = quantile(vals, 0.975)
    )
  })

  summary_list <- purrr::compact(summary_list)

  if (length(summary_list) == 0) {
    warning("No valid posterior random effects found for targeted_id; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  summary_df <- dplyr::bind_rows(summary_list)

  if (is.null(summary_df) || nrow(summary_df) == 0) {
    warning("Could not locate any 'r_targeted_id' random effect columns in Bayesian draws; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  summary_df |>
    arrange(desc(iasa_over_expected_mean))
}

# --- Main Execution ---

if (sys.nframe() == 0) {
  # Source path helpers
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  # Determine input/output directory
  PROC_DIR <- get_proc_dir()

  # Load FULL dataset
  analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
  if (!file.exists(analysis_path)) {
    # Fallback to W1 if full not ready
    if (file.exists(file.path(PROC_DIR, "analysis_w01.rds"))) {
      warning("analysis_full.rds not found. Using Week 1 data.")
      analysis_path <- file.path(PROC_DIR, "analysis_w01.rds")
    } else {
      stop("No analysis data found. Run 02_compute_IASA.R first.")
    }
  }

  df <- readRDS(analysis_path)

  # Ensure supplementary categorical variables exist and are usable (no NAs, factors)
  if (!"offense_formation" %in% names(df)) df$offense_formation <- NA_character_
  if (!"receiver_alignment" %in% names(df)) df$receiver_alignment <- NA_character_
  if (!"route_of_targeted_receiver" %in% names(df)) df$route_of_targeted_receiver <- NA_character_
  if (!"team_coverage_man_zone" %in% names(df)) df$team_coverage_man_zone <- NA_character_
  if (!"team_coverage_type" %in% names(df)) df$team_coverage_type <- NA_character_

  df <- df |>
    mutate(
      offense_formation = factor(replace_na(offense_formation, "Unknown")),
      receiver_alignment = factor(replace_na(receiver_alignment, "Unknown")),
      route_of_targeted_receiver = factor(replace_na(route_of_targeted_receiver, "Unknown")),
      team_coverage_man_zone = factor(replace_na(team_coverage_man_zone, "Unknown")),
      team_coverage_type = factor(replace_na(team_coverage_type, "Unknown"))
    )

  # --- Debugging Missing Values ---
  message(paste("Total rows loaded:", nrow(df)))

  missing_stats <- df |>
    summarise(
      missing_IASA = sum(is.na(IASA)),
      missing_air_time = sum(is.na(air_time)),
      missing_d_throw = sum(is.na(d_throw)),
      missing_d_catch = sum(is.na(d_catch)),
      missing_targeted_id = sum(is.na(targeted_id)),
      zero_air_time = sum(air_time == 0, na.rm = TRUE),
      negative_air_time = sum(air_time < 0, na.rm = TRUE)
    )

  print("Missing Value Counts:")
  print(missing_stats)

  # Filter for valid data
  # IMPORTANT: Ensure targeted_id is a factor for random effects
  df_model <- df |>
    drop_na(IASA, air_time, d_throw, targeted_id, pass_length, defenders_in_the_box) |>
    filter(air_time >= 0) |> # Allow 0 air time? No, but >= just in case floating point issues
    mutate(
      targeted_id = as.factor(targeted_id),
      game_id = as.factor(game_id),
      air_time_scaled = scale(air_time)[, 1],
      d_throw_scaled = scale(d_throw)[, 1],
      pass_length_scaled = scale(pass_length)[, 1],
      defenders_in_the_box_scaled = scale(defenders_in_the_box)[, 1]
    )

  message(paste("Fitting model on", nrow(df_model), "plays."))

  # NOTE: If the dataset is small (e.g., only Week 1 valid plays),
  # random effects might be estimated as zero (singular fit).
  # This is expected with sparse data.

  # Fit Model
  mem_model <- fit_mixed_effects_model(df_model)

  if (lme4::isSingular(mem_model)) {
    message("Warning: mixed-effects model fit is singular.")
  }

  # Print Summary
  print(summary(mem_model))

  # --- Model validation metrics (in-sample) ---
  y_obs <- df_model$IASA
  y_hat <- fitted(mem_model)
  resid <- y_obs - y_hat

  rmse <- sqrt(mean(resid^2, na.rm = TRUE))
  mae <- mean(abs(resid), na.rm = TRUE)
  r2 <- 1 - var(resid, na.rm = TRUE) / var(y_obs, na.rm = TRUE)

  mem_metrics <- tibble(
    metric = c("RMSE", "MAE", "Pseudo_R2"),
    value  = c(rmse, mae, r2)
  )

  message("Mixed-effects model metrics:")
  print(mem_metrics)

  # --- Diagnostic figures ---
  diag_df <- tibble(
    IASA = y_obs,
    fitted = y_hat,
    resid = resid
  )

  # Determine figure directory
  FIG_DIR <- get_fig_dir()

  p_fit <- ggplot(diag_df, aes(x = fitted, y = IASA)) +
    geom_point(alpha = 0.3, color = "#0072B2") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    theme_minimal() +
    labs(
      title = "Mixed-Effects Model: Fitted vs Observed IASA",
      x = "Fitted IASA",
      y = "Observed IASA"
    )

  ggsave(
    filename = file.path(FIG_DIR, "mixed_effects_fitted_vs_observed.png"),
    plot = p_fit,
    width = 8, height = 5, dpi = 300
  )

  p_resid <- ggplot(diag_df, aes(x = resid)) +
    geom_histogram(bins = 40, fill = "#D55E00", color = "white", alpha = 0.8) +
    theme_minimal() +
    labs(
      title = "Mixed-Effects Model Residuals (IASA)",
      x = "Residual",
      y = "Count"
    )

  ggsave(
    filename = file.path(FIG_DIR, "mixed_effects_residuals_hist.png"),
    plot = p_resid,
    width = 8, height = 5, dpi = 300
  )

  # Extract and Save Rankings
  rankings <- extract_receiver_rankings(mem_model)

  # Join with player names from analysis data if available
  if ("targeted_name" %in% names(df)) {
    name_map <- df |>
      distinct(targeted_id, targeted_name) |>
      mutate(targeted_id = as.character(targeted_id))

    rankings <- rankings |>
      left_join(name_map, by = c("nfl_id" = "targeted_id")) |>
      relocate(targeted_name, .before = nfl_id)
  }

  print(head(rankings, 10))

  # Fit Bayesian version of the mixed-effects model (if brms is available)
  bayes_model <- fit_bayesian_iasa_model(df_model)
  bayes_rankings <- extract_bayesian_receiver_rankings(bayes_model)

  if (!is.null(bayes_model) && !is.null(bayes_rankings)) {
    if ("targeted_name" %in% names(df)) {
      name_map <- df |>
        distinct(targeted_id, targeted_name) |>
        mutate(targeted_id = as.character(targeted_id))

      bayes_rankings <- bayes_rankings |>
        left_join(name_map, by = c("nfl_id" = "targeted_id")) |>
        relocate(targeted_name, .before = nfl_id)
    }

    message("Bayesian mixed-effects model for IASA fit successfully.")
    print(head(bayes_rankings, 10))

    saveRDS(bayes_model, file.path(PROC_DIR, "mixed_effects_model_bayes.rds"))
    write_csv(bayes_rankings, file.path(PROC_DIR, "receiver_rankings_bayes.csv"))
  } else {
    message("Bayesian IASA model not fit; skipping Bayesian rankings export.")
  }

  # Save outputs
  saveRDS(mem_model, file.path(PROC_DIR, "mixed_effects_model.rds"))
  write_csv(rankings, file.path(PROC_DIR, "receiver_rankings.csv"))
  write_csv(mem_metrics, file.path(PROC_DIR, "mixed_effects_metrics.csv"))

  message(paste("Saved model and rankings to", PROC_DIR))
}
```

### 3.4 Predictive Modeling of Final Separation (XGBoost)

While the mixed‑effects model attributes skill to receivers, we also ask a complementary question: **given what we know at the throw, how much separation should we expect at the catch?** To answer this, we fit a gradient‑boosted tree model (XGBoost) to predict \(d_{catch}\) using only pre‑throw or contemporaneous features, including:

- Initial separation \(d_{throw}\).
- Air time.
- Play context (down, distance, field position).
- Aggregated route/coverage indicators and defensive structure variables.

We train the model on a subset of plays and hold out a test set to evaluate performance. Our primary metric is **Root Mean Squared Error (RMSE)** in yards, supplemented by visual inspection of predicted vs. observed separation and a feature importance analysis.

Unlike the mixed‑effects model, which is built around interpretability and receiver random effects, XGBoost is optimized for predictive accuracy and can capture **non‑linear interactions** between features (e.g., how air time interacts with initial separation differently on certain route types).

```{r}
#| label: code-xgboost
#| eval: false
# Exact code used to train the XGBoost model for final separation.

# 07_ml_models.R
# Description: Predict Final Separation using Gradient Boosting (XGBoost).
# Goal: Predict d_catch (or IASA) using pre-throw features.

library(tidyverse)

if (!requireNamespace("xgboost", quietly = TRUE) ||
  !requireNamespace("caret", quietly = TRUE)) {
  stop("Packages 'xgboost' and 'caret' are required for 07_ml_models.R. Please install them.")
}

# --- Functions ---

prepare_ml_data <- function(analysis_df) {
  # Select features for ML
  # We want to predict d_catch (or IASA)
  # Features: core separation metrics + route / coverage / context

  # Only use columns that actually exist (for robustness)
  desired_cols <- c(
    "d_catch", # target
    "d_throw",
    "air_time",
    "pass_length",
    "defenders_in_the_box",
    "expected_points",
    "expected_points_added",
    "yards_gained",
    "offense_formation",
    "receiver_alignment",
    "route_of_targeted_receiver",
    "team_coverage_man_zone",
    "team_coverage_type",
    "pass_location_type",
    "dropback_type"
  )

  available <- intersect(desired_cols, names(analysis_df))

  ml_df <- analysis_df |>
    select(all_of(available)) |>
    # Ensure target is present
    filter(!is.na(d_catch), !is.na(d_throw), !is.na(air_time)) |>
    # Handle categorical predictors as factors with explicit 'Unknown' level
    mutate(
      across(
        where(is.character),
        ~ factor(replace_na(.x, "Unknown"))
      )
    )

  ml_df
}

train_xgboost <- function(ml_df) {
  # Split Data
  set.seed(123)
  train_index <- caret::createDataPartition(ml_df$d_catch, p = 0.8, list = FALSE)
  train_data <- ml_df[train_index, ]
  test_data <- ml_df[-train_index, ]

  # Matrix format for XGBoost (one-hot encode factors)
  train_matrix <- model.matrix(d_catch ~ . - 1, data = train_data)
  test_matrix <- model.matrix(d_catch ~ . - 1, data = test_data)

  dtrain <- xgboost::xgb.DMatrix(
    data = train_matrix,
    label = train_data$d_catch
  )

  dtest <- xgboost::xgb.DMatrix(
    data = test_matrix,
    label = test_data$d_catch
  )

  # Parameters
  params <- list(
    objective = "reg:squarederror",
    eta = 0.1,
    max_depth = 6,
    subsample = 0.8,
    colsample_bytree = 0.8
  )

  # Train
  message("Training XGBoost model...")
  model <- xgboost::xgb.train(
    params = params,
    data = dtrain,
    nrounds = 100,
    watchlist = list(train = dtrain, test = dtest),
    print_every_n = 10,
    early_stopping_rounds = 10
  )

  # Feature Importance
  importance <- xgboost::xgb.importance(model = model)
  importance_plot <- xgboost::xgb.plot.importance(importance_matrix = importance)

  # --- Validation metrics ---
  # Predictions on train and test
  pred_train <- predict(model, dtrain)
  pred_test <- predict(model, dtest)

  obs_train <- train_data$d_catch
  obs_test <- test_data$d_catch

  rmse_train <- sqrt(mean((obs_train - pred_train)^2, na.rm = TRUE))
  rmse_test <- sqrt(mean((obs_test - pred_test)^2, na.rm = TRUE))

  mae_train <- mean(abs(obs_train - pred_train), na.rm = TRUE)
  mae_test <- mean(abs(obs_test - pred_test), na.rm = TRUE)

  r2_train <- 1 - var(obs_train - pred_train, na.rm = TRUE) / var(obs_train, na.rm = TRUE)
  r2_test <- 1 - var(obs_test - pred_test, na.rm = TRUE) / var(obs_test, na.rm = TRUE)

  metrics <- tibble(
    split  = c("train", "test"),
    RMSE   = c(rmse_train, rmse_test),
    MAE    = c(mae_train, mae_test),
    R2     = c(r2_train, r2_test)
  )

  message("XGBoost validation metrics:")
  print(metrics)

  list(
    model = model,
    test_data = test_data,
    importance = importance,
    importance_plot = importance_plot,
    metrics = metrics,
    test_diag = tibble(
      obs  = obs_test,
      pred = pred_test
    )
  )
}

# --- Main Execution ---

if (sys.nframe() == 0) {
  if (dir.exists("processed")) {
    PROC_DIR <- "processed"
  } else if (dir.exists("../processed")) {
    PROC_DIR <- "../processed"
  } else {
    stop("Could not find 'processed' directory.")
  }

  analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
  if (!file.exists(analysis_path)) stop("analysis_full.rds not found.")

  df <- readRDS(analysis_path)

  message("Preparing ML dataset...")
  ml_data <- prepare_ml_data(df)

  res <- train_xgboost(ml_data)

  # Save Importance Plot (only if a ggplot object is returned)
  if (!dir.exists("figures")) dir.create("figures")
  if (inherits(res$importance_plot, "ggplot")) {
    importance_fig <- res$importance_plot + ggplot2::theme_minimal(base_size = 14)
    ggplot2::ggsave(
      filename = file.path("figures", "feature_importance.png"),
      plot = importance_fig,
      width = 8,
      height = 5,
      dpi = 300
    )
  } else {
    message("Feature importance plot not available; skipping feature_importance.png.")
  }

  # Predicted vs Observed plot (test set)
  p_pred <- ggplot(res$test_diag, aes(x = pred, y = obs)) +
    geom_point(alpha = 0.3, color = "#009E73") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    theme_minimal() +
    labs(
      title = "XGBoost: Predicted vs Observed d_catch (Test Set)",
      x = "Predicted d_catch",
      y = "Observed d_catch"
    )

  ggplot2::ggsave(
    filename = file.path("figures", "xgboost_pred_vs_observed.png"),
    plot = p_pred,
    width = 8,
    height = 5,
    dpi = 300
  )

  saveRDS(res$model, file.path(PROC_DIR, "xgboost_model.rds"))
  write_csv(res$metrics, file.path(PROC_DIR, "xgboost_metrics.csv"))
  message("Saved xgboost_model.rds, xgboost_metrics.csv, feature_importance.png, and xgboost_pred_vs_observed.png")
}
```

```{r}
#| label: code-visualizations
#| eval: false
# Exact code used to generate figures for IASA, routes, coverage, and Bayesian intervals.

# 04_visualizations.R
# Description: Generate plots and visualizations for reports.

library(tidyverse)
library(ggplot2)

plot_iasa_distribution <- function(data) {
  ggplot(data, aes(x = IASA)) +
    geom_histogram(binwidth = 0.5, fill = "#0072B2", color = "white", alpha = 0.8) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
    theme_minimal() +
    labs(
      title = "Distribution of In-Air Separation Added (IASA)",
      subtitle = "Full Data Analysis",
      x = "IASA (Yards Gained/Lost)",
      y = "Number of Plays",
      caption = "Positive IASA = Separation Gained | Negative IASA = Separation Lost"
    )
}

plot_iasa_vs_airtime <- function(data) {
  ggplot(data, aes(x = air_time, y = IASA)) +
    geom_point(alpha = 0.5, color = "#D55E00") +
    geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
    theme_minimal() +
    labs(
      title = "IASA vs. Air Time",
      subtitle = "Longer throws give defenders more time to close in",
      x = "Air Time (seconds)",
      y = "IASA (Yards)"
    )
}

plot_iasa_vs_throw_separation <- function(data) {
  ggplot(data, aes(x = d_throw, y = IASA)) +
    geom_point(alpha = 0.5, color = "#009E73") +
    geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
    theme_minimal() +
    labs(
      title = "IASA vs. Initial Separation at Throw",
      subtitle = "Regression to the mean: Open receivers tend to lose separation",
      x = "Separation at Throw (Yards)",
      y = "IASA (Yards)"
    )
}

# New: IASA by route of targeted receiver
plot_iasa_by_route <- function(data, min_plays = 50) {
  data |>
    filter(!is.na(route_of_targeted_receiver)) |>
    group_by(route_of_targeted_receiver) |>
    summarise(
      n = n(),
      avg_IASA = mean(IASA, na.rm = TRUE)
    ) |>
    filter(n >= min_plays) |>
    arrange(desc(avg_IASA)) |>
    mutate(route_of_targeted_receiver = fct_reorder(route_of_targeted_receiver, avg_IASA)) |>
    ggplot(aes(x = route_of_targeted_receiver, y = avg_IASA)) +
    geom_col(fill = "#0072B2") +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Average IASA by Route Type",
      subtitle = paste("Routes with at least", min_plays, "plays"),
      x = "Route of Targeted Receiver",
      y = "Average IASA (Yards)"
    )
}

# New: IASA by coverage type (man/zone)
plot_iasa_by_coverage <- function(data, min_plays = 50) {
  data |>
    filter(!is.na(team_coverage_man_zone)) |>
    group_by(team_coverage_man_zone) |>
    summarise(
      n = n(),
      avg_IASA = mean(IASA, na.rm = TRUE)
    ) |>
    filter(n >= min_plays) |>
    ggplot(aes(x = fct_reorder(team_coverage_man_zone, avg_IASA), y = avg_IASA)) +
    geom_col(fill = "#D55E00") +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Average IASA by Coverage Family",
      subtitle = paste("Man vs Zone concepts (at least", min_plays, "plays)"),
      x = "Coverage (Man/Zone)",
      y = "Average IASA (Yards)"
    )
}

# --- New: Bayesian interval plots for report ---

plot_bayesian_iasa_intervals <- function(rankings_bayes, top_n = 15) {
  # Visualize posterior mean and 95% CrI for IASA over expected
  if (!"iasa_over_expected_mean" %in% names(rankings_bayes)) {
    return(NULL)
  }

  if ("targeted_name" %in% names(rankings_bayes)) {
    rankings_bayes <- rankings_bayes |>
      mutate(label = targeted_name)
  } else {
    rankings_bayes <- rankings_bayes |>
      mutate(label = as.character(nfl_id))
  }

  rankings_bayes |>
    filter(!is.na(iasa_over_expected_mean)) |>
    slice_max(iasa_over_expected_mean, n = top_n, with_ties = FALSE) |>
    mutate(label = fct_reorder(label, iasa_over_expected_mean)) |>
    ggplot(aes(x = label, y = iasa_over_expected_mean)) +
    geom_point(color = "#0072B2") +
    geom_errorbar(
      aes(ymin = iasa_over_expected_lower, ymax = iasa_over_expected_upper),
      width = 0
    ) +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Top Receivers by IASA Over Expected (Bayesian)",
      subtitle = "Posterior mean and 95% credible intervals",
      x = "Receiver",
      y = "IASA Over Expected (Yards)"
    )
}

plot_bayesian_markov_intervals <- function(lift_bayes, top_n = 15) {
  # Visualize posterior mean and 95% CrI for break-open rates (Markov Lift)
  if (!"player_rate_mean" %in% names(lift_bayes)) {
    return(NULL)
  }

  # Handle both legacy and current column names for interval bounds
  # Legacy CSVs may have `player_rate_lower.2.5%` / `player_rate_upper.97.5%`.
  if ("player_rate_lower.2.5%" %in% names(lift_bayes) &&
    !"player_rate_lower" %in% names(lift_bayes)) {
    lift_bayes <- lift_bayes |>
      dplyr::rename(
        player_rate_lower = `player_rate_lower.2.5%`,
        player_rate_upper = `player_rate_upper.97.5%`
      )
  }

  # Use player name when available
  if ("targeted_name" %in% names(lift_bayes)) {
    lift_bayes <- lift_bayes |>
      mutate(label = targeted_name)
  } else {
    lift_bayes <- lift_bayes |>
      mutate(label = as.character(targeted_id))
  }

  # Ensure interval columns exist (they will, given how we write the CSV)
  lift_bayes |>
    filter(!is.na(player_rate_mean)) |>
    slice_max(player_rate_mean, n = top_n, with_ties = FALSE) |>
    mutate(
      label = fct_reorder(label, player_rate_mean),
      player_rate_pct = player_rate_mean
    ) |>
    ggplot(aes(x = label, y = player_rate_pct)) +
    geom_point(color = "#D55E00") +
    geom_errorbar(
      aes(
        ymin = player_rate_lower,
        ymax = player_rate_upper
      ),
      width = 0
    ) +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Top Receivers by Break-Open Rate (Bayesian Markov Lift)",
      subtitle = "Per-frame break-open probability with 95% credible intervals",
      x = "Receiver",
      y = "Break-Open Probability (%)"
    )
}

if (sys.nframe() == 0) {
  # Source path helpers
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  # Determine input directory
  PROC_DIR <- get_proc_dir()

  analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
  if (!file.exists(analysis_path)) {
    # Fallback to week 1 if full analysis not run yet
    analysis_path_w1 <- file.path(PROC_DIR, "analysis_w01.rds")
    if (file.exists(analysis_path_w1)) {
      warning("analysis_full.rds not found, using analysis_w01.rds")
      analysis_path <- analysis_path_w1
    } else {
      stop(paste(analysis_path, "not found. Run 02_compute_IASA.R first."))
    }
  }

  df <- readRDS(analysis_path)

  # Check for missing IASA values
  missing_iasa <- sum(is.na(df$IASA))
  if (missing_iasa > 0) {
    message(sprintf("Note: Removing %d rows where IASA could not be calculated (likely due to missing defender tracking data in output).", missing_iasa))
    df <- df[!is.na(df$IASA), ]
  }

  # Determine output directory
  FIG_DIR <- get_fig_dir()

  p1 <- plot_iasa_distribution(df)
  ggsave(file.path(FIG_DIR, "iasa_distribution.png"), p1, width = 8, height = 5)

  p2 <- plot_iasa_vs_airtime(df)
  ggsave(file.path(FIG_DIR, "iasa_vs_airtime.png"), p2, width = 8, height = 5)

  p3 <- plot_iasa_vs_throw_separation(df)
  ggsave(file.path(FIG_DIR, "iasa_vs_dthrow.png"), p3, width = 8, height = 5)

  # New contextual plots if supplementary data is present
  if ("route_of_targeted_receiver" %in% names(df)) {
    p4 <- plot_iasa_by_route(df)
    ggsave(file.path(FIG_DIR, "iasa_by_route.png"), p4, width = 8, height = 6)
  }

  if ("team_coverage_man_zone" %in% names(df)) {
    p5 <- plot_iasa_by_coverage(df)
    ggsave(file.path(FIG_DIR, "iasa_by_coverage.png"), p5, width = 8, height = 6)
  }

  # Bayesian IASA over expected intervals (if available)
  bayes_iasa_path <- file.path(PROC_DIR, "receiver_rankings_bayes.csv")
  if (file.exists(bayes_iasa_path)) {
    rankings_bayes <- read_csv(bayes_iasa_path, show_col_types = FALSE)
    p6 <- plot_bayesian_iasa_intervals(rankings_bayes, top_n = 15)
    if (!is.null(p6)) {
      ggsave(file.path(FIG_DIR, "receiver_iasa_bayes_intervals.png"), p6, width = 8, height = 6)
    }
  }

  # Bayesian Markov Lift intervals (if available)
  bayes_markov_path <- file.path(PROC_DIR, "markov_lift_rankings_bayes.csv")
  if (file.exists(bayes_markov_path)) {
    lift_bayes <- read_csv(bayes_markov_path, show_col_types = FALSE)
    p7 <- plot_bayesian_markov_intervals(lift_bayes, top_n = 15)
    if (!is.null(p7)) {
      ggsave(file.path(FIG_DIR, "markov_lift_bayes_intervals.png"), p7, width = 8, height = 6)
    }
  }

  message(paste("Saved figures to", FIG_DIR))
}
```

### 3.5 Reproducible Pipeline

All intermediate data products and model outputs flow through a scripted R pipeline. For reproducibility, the main steps are:

```{r}
#| label: full-pipeline
#| eval: false

# 1) Feature engineering and separation trajectories for each week
source("src/01_engineer_features.R")

# 2) Compute IASA and join supplementary play-level context
source("src/02_compute_IASA.R")

# 3) Fit mixed-effects model and write receiver rankings + metrics
source("src/03_models.R")

# 4) Compute Markov transition matrix and Markov Lift rankings
source("src/06_markov_separation.R")

# 5) Train XGBoost model and export feature importance + validation metrics
source("src/07_ml_models.R")
```

```{r}
#| label: code-utils-paths
#| eval: false
# Helper used throughout the pipeline to resolve processed/figures directories.

## utils_paths.R
## Helper functions for resolving project directories consistently.

get_proc_dir <- function() {
    if (dir.exists("processed")) {
        return("processed")
    }
    if (dir.exists("../processed")) {
        return("../processed")
    }
    stop("Could not find 'processed' directory.")
}

get_fig_dir <- function() {
    if (dir.exists("figures")) {
        return("figures")
    }
    if (dir.exists("../figures")) {
        return("../figures")
    }
    dir.create("figures", showWarnings = FALSE)
    "figures"
}
```

The scripts in `src/` write processed `.rds` and `.csv` files to `processed/`, which are in turn read by this Quarto document to generate tables and figures.

## 4. Results

### 4.1 Separation Dynamics (IASA)

Across the 14,108 passing plays in our sample, receivers **typically lose separation** during ball flight. The mean IASA is **−0.82 yards**, and the distribution is centered below zero with a long left tail:

- Many plays cluster near 0, where defenders and receivers maintain roughly constant separation.
- A substantial mass of plays shows moderate separation loss, consistent with defenders closing space on deeper throws.
- A smaller but important right tail captures plays where receivers gain meaningful separation in the air.

![Distribution of IASA](../figures/iasa_distribution.png)

From a football perspective, this baseline matters: if most plays lose separation, then simply maintaining or slightly improving separation is evidence of skill. It also highlights why raw “separation at catch” can be misleading without context—some receivers routinely fight back to neutral or positive IASA from difficult starting points.

### 4.2 Drivers of Separation Change

The mixed‑effects model quantifies how air time, initial separation, and context relate to IASA. Two core drivers emerge:

1. **Air Time**: Longer throws result in more lost separation. The estimated coefficient of approximately \(\beta_1 = -0.09\) (yards per second of air time, \(p < 0.01\)) implies that adding about half a second to a throw’s flight time costs, on average, an additional \(\approx 0.045\) yards of separation. This matches the intuition that deeper balls give defenders more time to recover.
2. **Initial Separation**: There is strong regression to the mean, with an estimated coefficient of \(\beta_2 \approx -0.39\) (\(p < 0.001\)). Routes that are very open at the throw tend to see some closure by the catch, while tightly contested throws occasionally drift toward more neutral separation.

![IASA vs Air Time](../figures/iasa_vs_airtime.png)
![IASA vs Initial Separation](../figures/iasa_vs_dthrow.png)

Model diagnostics show that fitted vs. observed IASA align reasonably well and residuals are roughly centered and symmetric:

![Mixed-Effects Fitted vs Observed](../src/figures/mixed_effects_fitted_vs_observed.png)
![Mixed-Effects Residuals](../src/figures/mixed_effects_residuals_hist.png)

These patterns suggest that the combination of air time, initial separation, and contextual covariates captures a meaningful portion of the variation in in‑air separation, while leaving room for receiver‑specific effects and unmeasured factors (e.g., quarterback ball placement, subtle contact downfield).

### 4.3 Markov Chain Analysis

We next examine separation as a frame‑level process. The estimated league‑wide transition matrix reveals that **states are sticky**: most frames remain in the same separation state on the next frame, especially in S2 (open) and S3 (wide open). However, non‑trivial movement occurs:

![Markov Transition Matrix](../figures/markov_transitions.png)

From this matrix, the league‑average probability of **breaking open**—transitioning from covered (S0/S1) to open (S2/S3) in a single frame—is **1.49%**. Because frames occur at 0.1‑second resolution, this may seem small, but across a typical 0.7–1.0 second ball flight there are multiple opportunities for change.

To identify receivers who are particularly adept at breaking open mid‑route, we compute Markov Lift as the difference between a receiver’s personal break‑open probability and the league baseline. Players with large positive Markov Lift values repeatedly convert tight/moderate coverage into open windows more often than expected, even after aggregating across many games. In addition to the empirical estimates, we fit a **Bayesian hierarchical model** for these break‑open rates, which partially pools low‑volume receivers toward the league average and provides posterior means and 95% credible intervals for each player’s propensity to break open.

**Top Receivers by Markov Lift** are shown below:

```{r}
#| label: load-markov-rankings
library(tidyverse)
library(knitr)

lift_path <- "../processed/markov_lift_rankings.csv"
lift_bayes_path <- "../processed/markov_lift_rankings_bayes.csv"

if (file.exists(lift_path)) {
  lift <- read_csv(lift_path)

  top_lift <- lift |>
    head(5) |>
    mutate(
      player_rate = paste0(round(player_rate * 100, 1), "%"),
      markov_lift = paste0("+", round(markov_lift * 100, 1), "%")
    )

  if ("targeted_name" %in% names(top_lift)) {
    top_lift |>
      select(targeted_id, targeted_name, player_rate, markov_lift) |>
      kable(col.names = c("ID", "Player", "Success Rate", "Markov Lift"))
  } else if ("displayName" %in% names(top_lift)) {
    top_lift |>
      select(targeted_id, displayName, player_rate, markov_lift) |>
      kable(col.names = c("ID", "Player", "Success Rate", "Markov Lift"))
  } else {
    top_lift |>
      select(targeted_id, player_rate, markov_lift) |>
      kable(col.names = c("ID", "Success Rate", "Markov Lift"))
  }
}

if (file.exists(lift_bayes_path)) {
  lift_bayes <- read_csv(lift_bayes_path) |>
    rename(
      player_rate_lower = `player_rate_lower.2.5%`,
      player_rate_upper = `player_rate_upper.97.5%`
    )

  top_lift_bayes <- lift_bayes |>
    head(5) |>
    mutate(
      player_rate = paste0(round(player_rate_mean * 100, 1), "%"),
      cr_interval = paste0(
        "[", round(player_rate_lower * 100, 1), "%, ",
        round(player_rate_upper * 100, 1), "%]"
      )
    )

  if ("targeted_name" %in% names(top_lift_bayes)) {
    top_lift_bayes |>
      select(targeted_id, targeted_name, player_rate, cr_interval) |>
      kable(col.names = c("ID", "Player", "Break-Open Rate", "95% CrI"))
  } else if ("displayName" %in% names(top_lift_bayes)) {
    top_lift_bayes |>
      select(targeted_id, displayName, player_rate, cr_interval) |>
      kable(col.names = c("ID", "Player", "Break-Open Rate", "95% CrI"))
  } else {
    top_lift_bayes |>
      select(targeted_id, player_rate, cr_interval) |>
      kable(col.names = c("ID", "Break-Open Rate", "95% CrI"))
  }
}
```

Receivers at the top of these tables often show Markov Lift values of several percentage points—for example, a player who breaks open 6.2% more often than league average on a per‑frame basis. The Bayesian table shows that many of these elevated break‑open rates remain above league average even after accounting for uncertainty, with wider intervals for low‑volume receivers and tighter intervals for high‑volume, consistently open separators.

![Bayesian Markov Lift Intervals](../src/figures/markov_lift_bayes_intervals.png)

Figure: Posterior mean break‑open probabilities and 95% credible intervals for the top break‑open receivers, highlighting which players are clearly above league baseline versus those whose apparent lift comes with wider uncertainty.

### 4.4 Predictive Modeling (XGBoost)

Our XGBoost model predicts final separation \(d_{catch}\) using pre‑throw information. On the held‑out test set, the model attains an RMSE of **1.79 yards**, meaning that predictions are typically within about two yards of the observed separation. While this is not precise enough to predict the exact contest level on every single play, it is sufficient to:

- Distinguish genuinely wide‑open looks from tightly contested targets.
- Identify situations (route and coverage combinations, air‑time regimes) that tend to generate open throws.

The model’s feature‑importance scores confirm that **initial separation \(d_{throw}\)** is the dominant predictor, followed by **air time**. Contextual variables (e.g., route/coverage features) contribute additional explanatory power but with smaller marginal importance. The predicted vs. observed plot shows points clustered along the identity line with moderate scatter:

![XGBoost Predicted vs Observed](../src/figures/xgboost_pred_vs_observed.png)

Feature importance from the fitted model is shown below, summarizing which inputs contribute most to predictive accuracy:

![XGBoost Feature Importance](../figures/feature_importance.png)

This behavior is consistent with a noisy, high‑variance outcome where much of the remaining uncertainty reflects factors not fully captured in our features, such as precise ball placement, hand‑fighting downfield, and micro‑adjustments at the catch point.

### 4.5 Top Receivers (IASA Over Expected)

Finally, we leverage the mixed‑effects model to produce **receiver‑level rankings** based on IASA over expected. For each receiver with sufficient volume, we extract their estimated random effect \(u_{\text{receiver}}\), which measures how much in‑air separation they add or lose relative to a context‑matched baseline.

```{r}
#| label: load-rankings
rankings_path <- "../processed/receiver_rankings.csv"
if(file.exists(rankings_path)) {
  rankings <- read_csv(rankings_path)

  top_rank <- rankings |>
    head(10)

  if ("targeted_name" %in% names(top_rank)) {
    top_rank |>
      select(nfl_id, targeted_name, iasa_over_expected) |>
      kable(col.names = c("ID", "Player", "IASA Over Expected"), digits = 3)
  } else if ("displayName" %in% names(top_rank)) {
    top_rank |>
      select(nfl_id, displayName, iasa_over_expected) |>
      kable(col.names = c("ID", "Player", "IASA Over Expected"), digits = 3)
  } else {
    top_rank |>
      select(nfl_id, iasa_over_expected) |>
      kable(col.names = c("ID", "IASA Over Expected"), digits = 3)
  }
}
```

```{r}
#| label: load-bayesian-rankings
rankings_bayes_path <- "../processed/receiver_rankings_bayes.csv"
if (file.exists(rankings_bayes_path)) {
  rankings_bayes <- read_csv(rankings_bayes_path)

  top_rank_bayes <- rankings_bayes |>
    head(10) |>
    mutate(
      iasa_mean = round(iasa_over_expected_mean, 3),
      iasa_cri = paste0(
        "[", round(iasa_over_expected_lower, 3), ", ",
        round(iasa_over_expected_upper, 3), "]"
      )
    )

  if ("targeted_name" %in% names(top_rank_bayes)) {
    top_rank_bayes |>
      select(nfl_id, targeted_name, iasa_mean, iasa_cri) |>
      kable(col.names = c("ID", "Player", "IASA OE (Mean)", "95% CrI"))
  } else if ("displayName" %in% names(top_rank_bayes)) {
    top_rank_bayes |>
      select(nfl_id, displayName, iasa_mean, iasa_cri) |>
      kable(col.names = c("ID", "Player", "IASA OE (Mean)", "95% CrI"))
  } else {
    top_rank_bayes |>
      select(nfl_id, iasa_mean, iasa_cri) |>
      kable(col.names = c("ID", "IASA OE (Mean)", "95% CrI"))
  }
}
```

Receivers with large positive IASA‑over‑expected values consistently **beat the model**: even after accounting for air time, initial separation, and context, they end up more open at the catch than expected. The Bayesian rankings show that many of these positive effects are statistically well‑separated from zero, while players with few targets or borderline effects have much wider credible intervals, reflecting “boom‑bust” versus steady separator profiles. Conversely, receivers with negative values may rely more heavily on scheme or timing, tending to lose separation in the air relative to comparable situations. Comparing these rankings with Markov Lift highlights players who both **gain net separation** and **frequently break open** mid‑route.

![Bayesian IASA Over Expected Intervals](../src/figures/receiver_iasa_bayes_intervals.png)

Figure: Posterior mean IASA over expected and 95% credible intervals for the top receivers, distinguishing reliable separators with tight intervals from higher‑variance “boom‑bust” profiles.

## 5. Discussion

Our multi‑method analysis paints a coherent picture of in‑air receiver movement in the NFL:

1. **Baseline dynamics**: Most plays lose separation while the ball is in the air (average IASA −0.82 yards), especially on deeper, longer‑air‑time throws. This sets a challenging baseline: doing “better than zero” requires meaningful skill.
2. **Skill vs. context**: Mixed‑effects modeling shows that initial separation and air time explain a significant portion of IASA, but non‑trivial receiver‑level random effects remain, capturing genuine differences in in‑air separation skill.
3. **Breaking open**: Markov‑chain analysis reframes separation as a sequence of coverage states and reveals that elite receivers break open from tight/moderate coverage more often than league average. A player with, for example, +6.2 percentage points of Markov Lift is repeatedly creating windows the quarterback would not otherwise have, and the Bayesian version of this model shows which of these elevated rates remain clearly above league average once uncertainty is taken into account.
4. **Predictability and design**: The XGBoost model demonstrates that much of final separation is predictable from pre‑throw information, underscoring the role of **play design and defensive structure**. However, residual variation and receiver‑level effects indicate that individual skill still matters even in favorable or unfavorable contexts.

Taken together, these results suggest that separation should be viewed as a **dynamic, shared product** of scheme, quarterback decision‑making, and receiver movement skill. IASA and Markov Lift help attribute credit within that shared process, while the Bayesian models add an explicit notion of **risk–reward** by distinguishing receivers with stable, tightly estimated advantages from those whose value comes with much wider uncertainty.

## 6. Limitations

Several limitations are important when interpreting our findings:

- **Single‑season sample**: Our analysis uses one regular season (2023). Receiver skill and team schemes evolve over time, so multi‑year stability of IASA and Markov Lift remains an open question.
- **Tracking noise and event timing**: Imperfect alignment of throw and catch frames, as well as small positional errors in tracking, introduce noise into both IASA and the frame‑level state sequences.
- **Context coverage**: While we include route and coverage families and basic game context, we do not fully capture quarterback progression, protection quality, or detailed defensive techniques (e.g., bracket coverage, leverage calls).
- **Modeling assumptions**: The linear mixed‑effects model assumes linear relationships and Gaussian random effects, and the Markov chain assumes first‑order dependence. Real routes may have longer memory and more complex, non‑linear patterns.
- **Attribution**: Positive IASA and Markov Lift are attributed to receivers, but in practice they also reflect quarterback play, play‑calling, and opponent quality.

These limitations do not invalidate our results but should temper over‑interpretation of individual rankings or model outputs.

## 7. Future Work

There are several promising directions to extend this work:

- **Route Types**: Incorporate more granular route labels (e.g., go vs. curl vs. dig) as fixed effects or interaction terms to understand which route structures most reward in‑air separation skill.
- **Ball Location**: Account explicitly for ball placement (underthrows, back‑shoulder throws, high/low targets), which can both enable and constrain how receivers create separation at the catch point.
- **Defensive Positioning**: Enrich the feature set with defender orientation, speed, and leverage, allowing us to distinguish separation created by receiver movement from separation granted by defensive decisions.
- **Multi‑season Stability**: Track IASA and Markov Lift over multiple seasons to assess stability and year‑to‑year persistence, which is critical for scouting and contract decisions.
- **Integration with Outcome Metrics**: Link in‑air separation metrics more directly to catch probability, yards after catch, and EPA to quantify how much in‑air separation actually translates into on‑field value.

By deepening the link between tracking data and on‑field decision‑making, these extensions could make IASA and Markov Lift even more actionable for teams and analysts.
