---
title: "Technical Report: Receiver Movement during Ball Flight"
author: "Eleanor Brothers, Kalynn Willis, Jasmine Peck"
date: 12/02/2025
format:
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  echo: true
  warning: false
  message: false
---

## Executive Summary

### Overview

NFL tracking data tells us how open a receiver is at the throw and at the catch, but it rarely answers a crucial question: *what happened while the ball was in the air?* Defenders are reacting, the ball is traveling, and receivers are fighting for position, yet most public metrics only capture two snapshots in time. This project introduces **Ball Flight Differential(BFD)**, a play‑level measure of how much separation a targeted receiver gains or loses between the throw and the arrival of the ball, and combines it with a **Markov Lift** metric and a predictive model for final separation.

Using 2023 regular‑season tracking data from the Big Data Bowl (Weeks 1–18), we reconstruct the full separation trajectory for every targeted receiver. We define BFD as the change in receiver–defender distance during ball flight, categorize separation into four intuitive states (tight, moderate, open, wide open), and model transitions between these states as a Markov chain. On top of this, we fit a mixed‑effects model to separate receiver skill from play context and an XGBoost model that predicts separation at the catch from pre‑throw and situational features.

### Approach

Our analysis proceeds in four steps:

1. **Play‑level separation**: For each targeted play, we identify the throw and catch (or arrival) frames, compute distance to the nearest defender each frame, and define BFD (Ball-Flight Differential) as the difference between separation (differential) at the catch and at the throw.
2. **Differential dynamics**: We discretize separation into four states and estimate a league‑wide transition matrix that describes how often receivers move between states frame‑to‑frame. We then compute **Markov Lift** for each receiver: how often they “break open” from tight/moderate to open/wide‑open relative to league average.
3. **Context‑adjusted skill**: We fit a linear mixed‑effects model for BFD that includes air time, initial differential, and contextual play features as fixed effects and receiver/game effects as random effects. The receiver‑level random effects define **BFD over expected**.
4. **Predictive model**: We train an XGBoost model to predict final differential using only pre‑throw information (including $d_{throw}$, air time, and play context), and evaluate its performance on a held‑out test set.

### Main Findings

League‑wide, receivers usually **lose separation** while the ball is in the air: the mean BFD is **−0.82 yards**, reflecting how defenders naturally close space on most throws, especially deeper passes with longer air time. Longer air time and larger initial differential are both associated with more negative BFD, consistent with regression to the mean and the extra time defenders have to recover. Despite this baseline, a subset of receivers consistently generate **positive BFD over expected**, adding separation even after accounting for route, coverage, and situational factors.

From the Markov‑chain perspective, separation states are “sticky” from frame to frame, but **breaking open** from tight or moderate coverage is still observable and varies across players. The league‑wide probability of moving from a covered state (tight/moderate) to an open state (open/wide‑open) is **1.49% per frame**, while top receivers exceed this by several percentage points. Our predictive model attains an RMSE of **1.79 yards** for final separation and confirms that initial differential and air time are the dominant predictive features, with context variables providing incremental but smaller gains.

### Implications

For front offices and coaches, this work separates **who created separation** from **who merely benefited from the call or coverage**. BFD over expected attributes in‑air movement skill to receivers after adjusting for down‑and‑distance, route concepts, coverage family, and box count. Markov Lift reframes separation as a **sequence of coverage states** and highlights which receivers are most likely to break open late in the route, a key skill in third‑down and red‑zone situations. The predictive model offers a complementary lens, identifying situations that are inherently separation‑friendly even before the ball is thrown. Together, these tools provide a framework for scouting receivers, designing route concepts, and communicating data‑driven insights in football language rather than purely statistical terms.

## Introduction

### Motivation and Problem Statement

In the NFL, how many yards a receiver is away from their defender is typically recorded at either the throw or the catch, but this metric is incomplete – while the ball is in the air, strong receivers may create additional space from the defender or defenders may gain yards on the receiver.

### Football Example

For example, during a week 7 Saints-Bears game in the 2025 regular season, the New Orleans Saints wide receiver Chris Olave caught a 57-yard catch completion to advance his team to the 20-yard line. A replay of this play can be viewed here: [Chris Olave 57-yard catch vs Bears (Week 7, 2025)](https://www.youtube.com/watch?v=Fxqq43Bfyf4).

Throughout the play, Chris Olave appears to gain yards on his defender after the ball was thrown, allowing him more space to catch the ball and secure further yards. This type of example motivates our central question: which receivers consistently create or maintain separation while the ball is in the air?

Determining which receivers can shake their defender is important for their teammates, coaches, scouts, and fans alike. If a quarterback knows a receiver is skilled, they may be able to throw to them in a critical situation and trust that they can generate space from their defender and get open for the throw. Coaches and scouts can use this information to build their team when drafting new wide receivers – if a wide receiver had caught many throws to gain many yards with a previous team, it is imperative to understand if that was their skill alone or due to a good quarterback. Finally, fans can even use this information when drafting their fantasy football team. Receivers who consistently gain separation are more likely to secure catches and generate scoring opportunities, making them reliable fantasy contributors.

The Big Data Bowl tracking data allows us to examine these receiver-defender situations more closely. We convert this raw position data into metrics that analyze how much separation is gained or lost while the ball is in the air and identify receiver skill and their capability to shake off their nearest defender.

### Research Questions
To generate our metrics, we address the following questions:
How many yards do receivers typically gain or lose from their nearest defender throughout the throw time?
When controlling for other factors that influence ball-flight differential (defenders, teams, and situations), who are the best receivers?


## Data Description

### Data Sources

To address our research questions, we use the Big Data Bowl 2026 tracking and play-level data that covers the 2023 NFL regular season (Weeks 1 - 18). The play-level data includes game context (down, distance, time, score), offensive/defensive descriptors, and event-level identifiers like catch or incompletion. In addition, the tracking data contains frame-level positions for all of the players and the ball at 10 Hz. The focus of our project is on tracking moments from the throw to the end of the play, so that we can analyze the receiver-defender interactions when a ball is thrown.

```{r}
#| label: code-load-data
#| eval: false
# Exact code used to ingest weekly input/output CSVs from the Big Data Bowl.

# 00_load_data.R


library(tidyverse)
library(readr)

if (dir.exists("data")) {
  DATA_DIR <- "data"
} else if (dir.exists("../data")) {
  DATA_DIR <- "../data"
} else {
  warning("Could not find data/ directory. Assuming 'data' but might fail.")
  DATA_DIR <- "data"
}

WEEKS <- sprintf("w%02d", 1:18) # Weeks w01 to w18

load_week_data <- function(week) {
  input_file <- file.path(DATA_DIR, paste0("input_2023_", week, ".csv"))
  output_file <- file.path(DATA_DIR, paste0("output_2023_", week, ".csv"))

  if (!file.exists(input_file)) {
    warning(paste("Input file not found:", input_file))
    return(NULL)
  }
  if (!file.exists(output_file)) {
    warning(paste("Output file not found:", output_file))
    return(NULL)
  }
  input_data <- read_csv(input_file, show_col_types = FALSE)
  output_data <- read_csv(output_file, show_col_types = FALSE)

  return(list(input = input_data, output = output_data))
}

load_tracking_data <- function(weeks = WEEKS) {

  all_data <- list()

  for (week in weeks) {
    week_data <- load_week_data(week)
    if (!is.null(week_data)) {
      all_data[[week]] <- week_data
    }
  }

  return(all_data)
}

if (sys.nframe() == 0) {
  if (length(list.files(DATA_DIR, pattern = "\\.csv$")) == 0) {
    stop("No CSV files found in data/ directory. Please download the Big Data Bowl data.")
  }

  data <- load_tracking_data()
}
```

### Sample Construction

To narrow down the data, we filter to only the plays with an identified targeted receiver, throw frame, and play end frame. We remove any plays where tracking may be incomplete during a ball’s flight. Finally, we computed the distance between the identified receiver and the closest defender at each individual frame from the throw to the play end.
Our filtered dataset contains 14,108 passing plays, which each contain the receiver-defender separation at the throw and play end, the air time, and the contextual variables (down, score, routes run, etc.)

```{r}
#| label: code-feature-engineering
#| eval: false
# Exact feature-engineering code used to construct play-level separation and trajectories.

# 01_engineer_features.R

library(tidyverse)
identify_targeted_receiver <- function(play_data) {
  tr <- play_data |>
    filter(player_role == "Targeted Receiver") |>
    distinct(nfl_id) |>
    pull(nfl_id)

  if (length(tr) == 0) {
    return(NA_integer_)
  } 
  if (length(tr) > 1) {
    warning("Multiple targeted receivers found in one play; taking first.")
    tr <- tr[1]
  }
  tr
}

calculate_separation <- function(receiver_loc, defenders_loc) {
  if (nrow(receiver_loc) == 0 || nrow(defenders_loc) == 0) {
    return(NA_real_)
  }
  rx <- receiver_loc$x[1]
  ry <- receiver_loc$y[1]
  dx <- defenders_loc$x
  dy <- defenders_loc$y
  min(sqrt((rx - dx)^2 + (ry - dy)^2))
}

compute_play_separation <- function(gid, pid, input_df, output_df) {
  play_in <- input_df |> filter(game_id == gid, play_id == pid)
  play_out <- output_df |> filter(game_id == gid, play_id == pid)

  if (nrow(play_in) == 0 || nrow(play_out) == 0) {
    return(NULL)
  }

  tr_id <- identify_targeted_receiver(play_in)
  if (is.na(tr_id)) {
    return(NULL)
  }

  throw_frame <- max(play_in$frame_id, na.rm = TRUE)
  rec_throw <- play_in |> filter(nfl_id == tr_id, frame_id == throw_frame)

  tr_name_vec <- play_in |>
    filter(nfl_id == tr_id) |>
    distinct(player_name) |>
    pull(player_name)

  tr_name <- if (length(tr_name_vec) > 0) tr_name_vec[1] else NA_character_

  tr_pos_vec <- play_in |>
    filter(nfl_id == tr_id) |>
    distinct(player_position) |>
    pull(player_position)

  tr_pos <- if (length(tr_pos_vec) > 0) tr_pos_vec[1] else NA_character_
  defs_throw <- play_in |>
    filter(player_role == "Defensive coverage", frame_id == throw_frame)

  if (nrow(defs_throw) == 0) {
    message(
      "No 'Defensive coverage' labels for game ", gid,
      ", play ", pid, "; using non-offensive players at throw_frame as defenders."
    )
    defs_throw <- play_in |>
      filter(!player_role %in% c("Targeted Receiver", "Passer", "Other Route Runner"), frame_id == throw_frame)
  }

  defender_ids <- unique(defs_throw$nfl_id)

  d_throw <- calculate_separation(rec_throw, defs_throw)

  #In-air frames
  rec_out <- play_out |> filter(nfl_id == tr_id)
  if (nrow(rec_out) == 0) {
    return(NULL)
  }

  first_out_frame <- min(rec_out$frame_id, na.rm = TRUE)
  catch_frame <- max(rec_out$frame_id, na.rm = TRUE)
  rec_catch <- rec_out |> filter(frame_id == catch_frame)

  defs_catch <- play_out |>
    filter(nfl_id %in% defender_ids, frame_id == catch_frame)

  d_catch <- calculate_separation(rec_catch, defs_catch)

  # Assume 10 Hz frame rate
  air_time <- (catch_frame - first_out_frame) * 0.1

  #Compute Separation Trajectory

  frames <- unique(rec_out$frame_id)

  traj_list <- map(frames, function(f) {
    rec_loc <- rec_out |> filter(frame_id == f)
    defs <- play_out |> filter(frame_id == f, nfl_id %in% defender_ids)

    tibble(
      game_id = gid,
      play_id = pid,
      frame_id = f,
      separation = calculate_separation(rec_loc, defs)
    )
  })

  traj_df <- bind_rows(traj_list)

  list(
    play_features = tibble(
      game_id = gid,
      play_id = pid,
      targeted_id = tr_id,
      targeted_name = tr_name,
      targeted_position = tr_pos,
      throw_frame = throw_frame,
      catch_frame = catch_frame,
      d_throw = d_throw,
      d_catch = d_catch,
      air_time = air_time,
      ball_land_x = first(play_in$ball_land_x),
      ball_land_y = first(play_in$ball_land_y)
    ),
    trajectory = traj_df
  )
}

build_play_feature_table <- function(week_data) {
  input_df <- week_data$input
  output_df <- week_data$output

  plays <- input_df |> distinct(game_id, play_id)

  all_features <- list()
  all_trajectories <- list()

  for (i in 1:nrow(plays)) {
    p <- plays[i, ]
    res <- compute_play_separation(p$game_id, p$play_id, input_df, output_df)

    if (!is.null(res)) {
      all_features[[length(all_features) + 1]] <- res$play_features
      all_trajectories[[length(all_trajectories) + 1]] <- res$trajectory
    }

    if (i %% 100 == 0) cat(".")
  }
  cat("\n")

  features_df <- if (length(all_features) > 0) dplyr::bind_rows(all_features) else tibble()
  traj_df <- if (length(all_trajectories) > 0) dplyr::bind_rows(all_trajectories) else tibble()

  list(
    features = features_df,
    trajectories = traj_df
  )
}

if (sys.nframe() == 0) {
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Cannot find utils_paths.R")
  }

  if (file.exists("src/00_load_data.R")) {
    source("src/00_load_data.R")
  } else if (file.exists("00_load_data.R")) {
    source("00_load_data.R")
  } else {
    stop("Cannot find 00_load_data.R")
  }

  OUT_DIR <- get_proc_dir()

  for (week in WEEKS) {
    week_data_list <- load_week_data(week)

    if (is.null(week_data_list)) {
      next
    }

    results <- build_play_feature_table(week_data_list)

    #save Features
    feat_file <- file.path(OUT_DIR, paste0("play_features_", week, ".rds"))
    saveRDS(results$features, feat_file)

    #save Trajectories
    traj_file <- file.path(OUT_DIR, paste0("separation_trajectories_", week, ".rds"))
    saveRDS(results$trajectories, traj_file)

    rm(week_data_list, results)
    gc()
  }
}
```

## Methodology

### Ball Flight Differential (BFD)

The play-level metric we have created is an Ball-Flight Differential added (BFD) model:
$$
BFD = d_{catch} - d_{throw},
$$

This measures the difference in distance (in yards) between the targeted receiver and nearest defender at the time of the throw and the ball arrival (catch, pass breakup, or incompletion). Note that a positive BFD indicates the receiver gained separation from their nearest defender, while a negative BFD indicates the defender got closer. 

```{r}
#| label: code-compute-BFD
#| eval: false
# Exact code used to compute BFD and join supplementary context.

# 02_compute_BFD.R
# Formula: BFD = d_catch - d_throw
# Interpretation:
#   Positive BFD -> Gained separation (Good for WR)
#   Negative BFD -> Lost separation (Good for DB)

library(tidyverse)

compute_BFD <- function(play_features) {
  play_features |>
    mutate(
      BFD = d_catch - d_throw,
      separation_change_pct = ifelse(d_throw > 0, (d_catch - d_throw) / d_throw, NA_real_),
      is_separation_gained = BFD > 0
    )
}

if (sys.nframe() == 0) {
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  PROC_DIR <- get_proc_dir()

  feature_files <- list.files(PROC_DIR, pattern = "play_features_w[0-9]+\\.rds", full.names = TRUE)

  if (length(feature_files) == 0) {
    stop(paste("No feature files found in", PROC_DIR, ". Run 01_engineer_features.R first."))
  }

  features <- purrr::map_dfr(feature_files, readRDS)
  analysis_df <- compute_BFD(features)
  SUPP_PATH <- NULL
  if (dir.exists("data")) {
    SUPP_PATH <- file.path("data", "BDB2026_supplementary_data.csv")
  } else if (dir.exists("../data")) {
    SUPP_PATH <- file.path("../data", "BDB2026_supplementary_data.csv")
  }

  if (!is.null(SUPP_PATH) && file.exists(SUPP_PATH)) {


    supp <- readr::read_csv(SUPP_PATH, show_col_types = FALSE) |>
      dplyr::select(
        game_id,
        play_id,
        season,
        week,
        play_description,
        offense_formation,
        receiver_alignment,
        route_of_targeted_receiver,
        pass_result,
        pass_length,
        pass_location_type,
        play_action,
        dropback_type,
        dropback_distance,
        defenders_in_the_box,
        team_coverage_man_zone,
        team_coverage_type,
        expected_points,
        expected_points_added,
        yards_gained
      )

    analysis_df <- analysis_df |>
      mutate(
        game_id = as.numeric(game_id),
        play_id = as.numeric(play_id)
      ) |>
      left_join(
        supp |>
          mutate(
            game_id = as.numeric(game_id),
            play_id = as.numeric(play_id)
          ),
        by = c("game_id", "play_id")
      )
  } else {
    message("Supplementary play-level data not found; proceeding without it.")
  }

  summary_stats <- analysis_df |>
    summarise(
      avg_BFD = mean(BFD, na.rm = TRUE),
      median_BFD = median(BFD, na.rm = TRUE),
      prop_positive = mean(BFD > 0, na.rm = TRUE),
      n_plays = n()
    )

  print(summary_stats)

  saveRDS(analysis_df, file.path(PROC_DIR, "analysis_full.rds"))
}
```

### Separation States and Markov Lift

To take a deeper look at our problem, we utilize the Markov Lift method. We begin by analyzing separation as a dynamic process, using categorical variables to make the distance at each frame distinct: 

- **S0 (Tight)**: \< 1 yard
- **S1 (Moderate)**: 1–3 yards
- **S2 (Open)**: 3–5 yards
- **S3 (Wide Open)**: \> 5 yards

We created a sequence for each play where each frame is assigned a separation category. We then model the probabilities with a first-order Markov chain that estimates the transition probabilities:  
$$
P(S_{t+1} = j \mid S_t = i), \quad i, j \in \{0,1,2,3\}.
$$

In words, we measure the probability of the separation category of the next frame given the previous one. The league-wide transition matrix measures how likely a receiver is to maintain or change separation from frame to frame. The change can either be stagnant, decreasing, or increasing. Next, conceptually grouping S0 and S1 into “covered” states and S2 and S3 into “open” states, we focus on the transition between these two groups. The following formula represents the probability of going from covered to open in a single frame:  
$$
p^{\text{league}}_{\text{break}} = P(S_{t+1} \in \{2,3\} \mid S_t \in \{0,1\})
$$

Per frame, this probability is 1.49%.

Next, we calculate this model’s probability for each receiver based on their frame-level transition. We define Markov Lift as: 
$$
\text{Markov Lift} = p^{\text{player}}_{\text{break}} - p^{\text{league}}_{\text{break}}.
$$

This percentage measures if an individual receiver breaks open from often than the league average (a positive result) or vice versa. 


```{r}
#| label: code-markov-lift
#| eval: false
# Exact code used to build Markov transitions and Markov Lift.

# 06_markov_separation.R

library(tidyverse)

# Define separation states (in yards)
# S0: < 1 yard (Tight)
# S1: 1-3 yards (Moderate)
# S2: 3-5 yards (Open)
# S3: > 5 yards (Wide Open)

get_state <- function(sep) {
  case_when(
    sep < 1 ~ "S0_Tight",
    sep < 3 ~ "S1_Moderate",
    sep < 5 ~ "S2_Open",
    TRUE ~ "S3_WideOpen"
  )
}

STATE_LEVELS <- c("S0_Tight", "S1_Moderate", "S2_Open", "S3_WideOpen")

load_trajectories <- function(proc_dir = "processed") {
  files <- list.files(proc_dir, pattern = "separation_trajectories_w[0-9]+\\.rds", full.names = TRUE)
  if (length(files) == 0) stop("No trajectory files found.")

  map(files, readRDS) |>
    dplyr::bind_rows()
}

compute_transitions <- function(traj_df) {
  traj_df |>
    arrange(game_id, play_id, frame_id) |>
    group_by(game_id, play_id) |>
    mutate(
      state = get_state(separation),
      next_state = lead(state)
    ) |>
    filter(!is.na(state), !is.na(next_state)) |>
    ungroup()
}

estimate_transition_matrix <- function(transitions) {
  transitions <- transitions |>
    mutate(
      state = factor(state, levels = STATE_LEVELS),
      next_state = factor(next_state, levels = STATE_LEVELS)
    )

  counts <- transitions |>
    count(state, next_state, .drop = FALSE)

  counts |>
    group_by(state) |>
    mutate(prob = ifelse(sum(n) > 0, n / sum(n), 0)) |>
    ungroup()
}

plot_transition_matrix <- function(trans_probs) {
  ggplot(trans_probs, aes(x = next_state, y = fct_rev(state), fill = prob)) +
    geom_tile() +
    geom_text(aes(label = round(prob, 2)), color = "white") +
    scale_fill_gradient(low = "navy", high = "red") +
    theme_minimal() +
    labs(
      title = "Separation State Transition Probabilities",
      subtitle = "Probability of moving from State Y to State X in next frame",
      x = "Next State",
      y = "Current State",
      fill = "Probability"
    )
}

compute_markov_lift <- function(transitions, features_df) {

  relevant_starts <- c("S0_Tight", "S1_Moderate")
  good_ends <- c("S2_Open", "S3_WideOpen")
  league_rate <- transitions |>
    filter(state %in% relevant_starts) |>
    summarise(
      success_rate = mean(next_state %in% good_ends)
    ) |>
    pull(success_rate)


  player_stats <- transitions |>
    inner_join(features_df, by = c("game_id", "play_id")) |>
    filter(state %in% relevant_starts) |>
    group_by(targeted_id) |>
    summarise(
      n_transitions = n(),
      successes = sum(next_state %in% good_ends),
      player_rate = successes / n_transitions
    ) |>
    filter(n_transitions >= 50) |> # Minimum sample size
    mutate(
      markov_lift = player_rate - league_rate
    ) |>
    arrange(desc(markov_lift))

  player_stats
}

compute_break_counts <- function(transitions, features_df, min_transitions = 50) {
  relevant_starts <- c("S0_Tight", "S1_Moderate")
  good_ends <- c("S2_Open", "S3_WideOpen")

  league_rate <- transitions |>
    filter(state %in% relevant_starts) |>
    summarise(
      success_rate = mean(next_state %in% good_ends)
    ) |>
    pull(success_rate)

  player_counts <- transitions |>
    inner_join(features_df, by = c("game_id", "play_id")) |>
    filter(state %in% relevant_starts) |>
    group_by(targeted_id) |>
    summarise(
      n_transitions = n(),
      successes = sum(next_state %in% good_ends),
      .groups = "drop"
    ) |>
    filter(n_transitions >= min_transitions)

  list(
    break_df = player_counts,
    league_rate = league_rate
  )
}

fit_bayesian_markov_model <- function(break_df) {
  if (!requireNamespace("brms", quietly = TRUE)) {
    warning("Package 'brms' not installed; skipping Bayesian Markov Lift model.")
    return(NULL)
  }

  break_df <- break_df |>
    mutate(targeted_id = as.factor(targeted_id))

  bayes_fit <- brms::brm(
    successes | trials(n_transitions) ~ 1 + (1 | targeted_id),
    data = break_df,
    family = binomial(),
    prior = c(
      brms::prior(normal(0, 2), class = "Intercept"),
      brms::prior(exponential(1), class = "sd")
    ),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    cores = min(4, parallel::detectCores()),
    control = list(adapt_delta = 0.95),
    refresh = 0
  )

  bayes_fit
}

extract_bayesian_markov_lift <- function(bayes_model, break_df, league_rate) {
  if (is.null(bayes_model) || nrow(break_df) == 0) {
    return(NULL)
  }

  post_prob <- brms::posterior_epred(
    bayes_model,
    newdata = break_df,
    re_formula = ~ (1 | targeted_id)
  )

  summaries <- t(apply(post_prob, 2, function(draws) {
    c(
      player_rate_mean  = mean(draws),
      player_rate_sd    = sd(draws),
      player_rate_lower = quantile(draws, 0.025),
      player_rate_upper = quantile(draws, 0.975),
      markov_lift_mean  = mean(draws) - league_rate,
      markov_lift_lower = quantile(draws - league_rate, 0.025),
      markov_lift_upper = quantile(draws - league_rate, 0.975)
    )
  }))

  summaries <- as_tibble(summaries)

  tibble(
    targeted_id = as.character(break_df$targeted_id),
    n_transitions = break_df$n_transitions,
    successes = break_df$successes
  ) |>
    bind_cols(summaries) |>
    arrange(desc(markov_lift_mean))
}

if (sys.nframe() == 0) {
  # Source path helpers
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  PROC_DIR <- get_proc_dir()

  traj <- load_trajectories(PROC_DIR)

  raw_features <- readRDS(file.path(PROC_DIR, "analysis_full.rds"))

  if (!all(c("pass_length", "targeted_position") %in% names(raw_features))) {
    warning("pass_length or targeted_position missing in analysis_full.rds; using all plays for Markov transitions and Lift.")

    features_df <- raw_features |>
      select(game_id, play_id, targeted_id)

    trans <- compute_transitions(traj)
  } else {
    features_df <- raw_features |>
      filter(
        !is.na(pass_length),
        pass_length > 0,
        targeted_position %in% c("WR", "TE")
      ) |>
      select(game_id, play_id, targeted_id, targeted_position, pass_length)

    valid_plays <- features_df |>
      distinct(game_id, play_id)

    trans <- compute_transitions(traj) |>
      inner_join(valid_plays, by = c("game_id", "play_id"))
  }

  tm <- estimate_transition_matrix(trans)
  print(tm)

  p <- plot_transition_matrix(tm)
  FIG_DIR <- get_fig_dir()
  ggsave(file.path(FIG_DIR, "markov_transitions.png"), p, width = 8, height = 6)

  lift <- compute_markov_lift(trans, features_df)

  df_names <- raw_features
  if ("targeted_name" %in% names(df_names)) {
    name_map <- df_names |>
      distinct(targeted_id, targeted_name) |>
      mutate(targeted_id = as.character(targeted_id))

    lift <- lift |>
      mutate(targeted_id = as.character(targeted_id)) |>
      left_join(name_map, by = "targeted_id") |>
      relocate(targeted_name, .before = targeted_id)
  }

  print(head(lift, 10))

  write_csv(lift, file.path(PROC_DIR, "markov_lift_rankings.csv"))

  break_info <- compute_break_counts(trans, features_df, min_transitions = 50)
  bayes_markov <- fit_bayesian_markov_model(break_info$break_df)
  bayes_lift <- extract_bayesian_markov_lift(bayes_markov, break_info$break_df, break_info$league_rate)

  if (!is.null(bayes_markov) && !is.null(bayes_lift)) {
    if ("targeted_name" %in% names(df_names)) {
      name_map <- df_names |>
        distinct(targeted_id, targeted_name) |>
        mutate(targeted_id = as.character(targeted_id))

      bayes_lift <- bayes_lift |>
        mutate(targeted_id = as.character(targeted_id)) |>
        left_join(name_map, by = "targeted_id") |>
        relocate(targeted_name, .before = targeted_id)
    }

    print(head(bayes_lift, 10))

    saveRDS(bayes_markov, file.path(PROC_DIR, "markov_lift_bayes_model.rds"))
    write_csv(bayes_lift, file.path(PROC_DIR, "markov_lift_rankings_bayes.csv"))
  } else {
    message("Bayesian Markov Lift model not fit; skipping Bayesian lift export.")
  }
}
```

### Predictors and Rationale

Our goal in the mixed‑effects model is to explain how much separation a receiver gains or loses while the ball is in the air. Each covariate is chosen to capture one of three ideas:

- **Opportunity for movement**: how much time and space the receiver has to change leverage mid‑route.
- **Coverage difficulty**: how constrained the receiver’s movement is by the defensive structure.
- **Route‑level context**: how much in‑air adjustment a particular route concept naturally allows.

#### Opportunity variables

These covariates describe the “canvas” on which in‑air separation can change:

- **Air Time (scaled)**: Longer throws provide more frames for defenders to close and receivers to separate. Because separation change is inherently time‑dependent, controlling for air time prevents deep throws from being treated as “better” simply because they last longer.
- **Distance at Throw (scaled)**: Starting leverage matters. A receiver who is already wide open at release should not be credited for “gaining” separation just because the defender begins far away.
- **Pass Length (scaled)**: A proxy for route depth. Deeper routes differ systematically in defender recovery behavior, ball flight, and the amount of space receivers can work with.

#### Coverage difficulty variables

These terms represent how challenging the coverage environment is for creating separation:

- **Defenders in the Box (scaled)**: Higher counts often correspond to tighter formations or heavier defensive fronts, which correlate with man coverage, press looks, or aggressive safety rotations that shape initial leverage and recovery angles.
- **Team coverage indicators (Man vs. Zone / coverage family)**: Coverage scheme determines defender responsibilities. In man coverage, separation changes primarily reflect one‑on‑one matchups; in zone, they reflect how well receivers find and exploit space between defenders.

#### Route‑level context

Routes differ substantially in how much in‑air adjustment they permit:

- **Route of Targeted Receiver**: A vertical “go” route offers more variance in in‑air separation than a shallow drag or quick out. Including route family prevents us from attributing route‑driven patterns (e.g., back‑shoulder fades, crossers vs. curls) to the receiver’s individual skill.

#### Random effects

Finally, we use random effects to respect the nested structure of the data:

- **Receiver random intercept $(1 \mid \text{targeted\_id})$**: Captures persistent, player‑specific deviations in BFD over expected after controlling for the fixed‑effect covariates—our notion of in‑air separation skill.
- **Game random intercept $(1 \mid \text{game\_id})$**: Accounts for shared game‑level conditions such as opponent quality, weather, and scheme tendencies that affect all plays within a game.

### Mixed‑Effects Model for BFD over Expected

Raw BFD conflates receiver skill with **context**: longer air‑time throws, high‑leverage downs, and certain route/coverage combinations are naturally harder environments in which to gain separation. To isolate receiver skill, we fit a **linear mixed‑effects model**:

$$
BFD_{\text{play}} = \beta_0
  + \beta_1 \cdot \text{Air Time}
  + \beta_2 \cdot d_{throw}
  + \mathbf{x}_{\text{play}}^\top \boldsymbol{\beta}
  + u_{\text{receiver}}
  + u_{\text{game}}
  + \epsilon,
$$

where:

- $\mathbf{x}_{\text{play}}$ encodes contextual fixed effects (e.g., route family, coverage family, box count, down‑and‑distance).
- $u_{\text{receiver}}$ is a receiver‑level random effect capturing **in‑air separation skill** not explained by context.
- $u_{\text{game}}$ is a game‑level random effect capturing shared conditions within a game (e.g., weather, opponent tendencies).
- $\epsilon$ is residual error.

We estimate the model using standard mixed‑effects software and summarize receiver skill via **BFD over expected**, defined as the estimated receiver random effect $u_{\text{receiver}}$. Intuitively, a receiver with $u_{\text{receiver}} = +0.4$ tends to finish plays with roughly 0.4 yards more in‑air separation than expected, conditional on their route mix and situations; a receiver with $u_{\text{receiver}} = -0.3$ tends to lose additional separation relative to expectation.

In our implementation, we standardize the continuous predictors (air time, $d_{throw}$, pass length, and defenders in the box) before fitting, so the model is actually fit on scaled versions of these variables. The equation above is written in terms of the original units for interpretability, but the reported coefficients in the model summaries correspond to one‑standard‑deviation changes in each continuous predictor rather than one‑yard or one‑second changes.

For football interpretability, we **restrict the modeling sample to wide receivers and tight ends on forward passes** and include **position (WR vs. TE) as a fixed effect**, allowing baseline separation change to differ by role. All such targets are included in the mixed‑effects and Bayesian models (with partial pooling shrinking low‑volume players toward the league mean), while we later apply a minimum‑volume cutoff when displaying leaderboards.

To quantify uncertainty in these receiver effects, we also fit a **Bayesian analogue** of the mixed‑effects model using weakly informative priors on the fixed effects and on the receiver/game random‑effect standard deviations. This yields a posterior distribution for each receiver’s BFD over expected, from which we report posterior means and 95% credible intervals; players with few targets naturally have wider intervals, reflecting greater uncertainty in their estimated in‑air separation skill.

Model diagnostics (fitted vs. observed BFD and residual distributions) are used to assess linearity, variance assumptions, and the contribution of random effects.

```{r}
#| label: code-mixed-effects
#| eval: false
# Exact code used for mixed-effects and Bayesian BFD over expected models.

# 03_models.R

library(tidyverse)
library(lme4)
library(broom.mixed) 

fit_mixed_effects_model <- function(data) {
  # Model BFD controlling for:
  # - Air Time (longer throws allow more convergence)
  # - Initial Differential (regression to the mean)
  # - Route / coverage context and defensive structure
  # - Random Effect: Receiver ID (The metric we want)
  # - Random Effect: Game ID (Game-specific conditions/weather)

  m <- lmer(
    BFD ~ air_time_scaled + d_throw_scaled + pass_length_scaled + defenders_in_the_box_scaled +
      team_coverage_man_zone + route_of_targeted_receiver + targeted_position +
      (1 | targeted_id) + (1 | game_id),
    data = data,
    REML = FALSE
  )
  return(m)
}

extract_receiver_rankings <- function(model) {
  ranefs <- ranef(model)$targeted_id

  ranefs |>
    as_tibble(rownames = "nfl_id") |>
    rename(BFD_over_expected = `(Intercept)`) |>
    arrange(desc(BFD_over_expected))
}

fit_bayesian_BFD_model <- function(data) {
  if (!requireNamespace("brms", quietly = TRUE)) {
    warning("Package 'brms' not installed; skipping Bayesian BFD model.")
    return(NULL)
  }

  bayes_fit <- brms::brm(
    BFD ~ air_time + d_throw + pass_length + defenders_in_the_box +
      team_coverage_man_zone + route_of_targeted_receiver + targeted_position +
      (1 | targeted_id) + (1 | game_id),
    data = data,
    family = gaussian(),
    prior = c(
      brms::prior(normal(0, 2), class = "Intercept"),
      brms::prior(normal(0, 1), class = "b"),
      brms::prior(exponential(1), class = "sd"),
      brms::prior(exponential(1), class = "sigma")
    ),
    iter = 4000,
    warmup = 1000,
    chains = 4,
    cores = min(4, parallel::detectCores()),
    control = list(adapt_delta = 0.95),
    refresh = 0
  )

  bayes_fit
}

extract_bayesian_receiver_rankings <- function(bayes_model) {
  if (is.null(bayes_model)) {
    return(NULL)
  }
  if (!requireNamespace("posterior", quietly = TRUE)) {
    warning("Package 'posterior' not available; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  draws <- brms::as_draws_df(bayes_model)

  if (!"targeted_id" %in% names(bayes_model$data)) {
    warning("Model data does not contain 'targeted_id'; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  receiver_ids <- unique(as.character(bayes_model$data$targeted_id))

  summary_list <- purrr::map(receiver_ids, function(rid) {
    cand_cols <- c(
      paste0("r_targeted_id[", rid, ",Intercept]"),
      paste0("r_targeted_id[", rid, ",(Intercept)]")
    )
    col_name <- cand_cols[cand_cols %in% names(draws)][1]
    if (is.na(col_name)) {
      return(NULL)
    }
    vals <- draws[[col_name]]
    tibble(
      nfl_id = rid,
      BFD_over_expected_mean = mean(vals),
      BFD_over_expected_sd = sd(vals),
      BFD_over_expected_lower = quantile(vals, 0.025),
      BFD_over_expected_upper = quantile(vals, 0.975)
    )
  })

  summary_list <- purrr::compact(summary_list)

  if (length(summary_list) == 0) {
    warning("No valid posterior random effects found for targeted_id; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  summary_df <- dplyr::bind_rows(summary_list)

  if (is.null(summary_df) || nrow(summary_df) == 0) {
    warning("Could not locate any 'r_targeted_id' random effect columns in Bayesian draws; skipping Bayesian receiver rankings.")
    return(NULL)
  }

  summary_df |>
    arrange(desc(BFD_over_expected_mean))
}

if (sys.nframe() == 0) {
  # Source path helpers
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  PROC_DIR <- get_proc_dir()

  analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
  if (!file.exists(analysis_path)) {
    if (file.exists(file.path(PROC_DIR, "analysis_w01.rds"))) {
      warning("analysis_full.rds not found. Using Week 1 data.")
      analysis_path <- file.path(PROC_DIR, "analysis_w01.rds")
    } else {
      stop("No analysis data found. Run 02_compute_BFD.R first.")
    }
  }

  df <- readRDS(analysis_path)

  if (!"offense_formation" %in% names(df)) df$offense_formation <- NA_character_
  if (!"receiver_alignment" %in% names(df)) df$receiver_alignment <- NA_character_
  if (!"route_of_targeted_receiver" %in% names(df)) df$route_of_targeted_receiver <- NA_character_
  if (!"team_coverage_man_zone" %in% names(df)) df$team_coverage_man_zone <- NA_character_
  if (!"team_coverage_type" %in% names(df)) df$team_coverage_type <- NA_character_
  if (!"pass_length" %in% names(df)) df$pass_length <- NA_real_
  if (!"pass_result" %in% names(df)) df$pass_result <- NA_character_
  if (!"targeted_position" %in% names(df)) df$targeted_position <- NA_character_

  df <- df |>
    mutate(
      offense_formation = factor(replace_na(offense_formation, "Unknown")),
      receiver_alignment = factor(replace_na(receiver_alignment, "Unknown")),
      route_of_targeted_receiver = factor(replace_na(route_of_targeted_receiver, "Unknown")),
      team_coverage_man_zone = factor(replace_na(team_coverage_man_zone, "Unknown")),
      team_coverage_type = factor(replace_na(team_coverage_type, "Unknown")),
      targeted_position = replace_na(targeted_position, "Unknown")
    )

  df_filtered <- df |>
    filter(
      !is.na(pass_length),
      pass_length > 0,
      targeted_position %in% c("WR", "TE")
    )

  missing_stats <- df_filtered |>
    summarise(
      missing_BFD = sum(is.na(BFD)),
      missing_air_time = sum(is.na(air_time)),
      missing_d_throw = sum(is.na(d_throw)),
      missing_d_catch = sum(is.na(d_catch)),
      missing_targeted_id = sum(is.na(targeted_id)),
      zero_air_time = sum(air_time == 0, na.rm = TRUE),
      negative_air_time = sum(air_time < 0, na.rm = TRUE)
    )
  print(missing_stats)

  df_model <- df_filtered |>
    drop_na(BFD, air_time, d_throw, targeted_id, pass_length, defenders_in_the_box) |>
    filter(air_time >= 0) |> # Allow 0 air time? No, but >= just in case floating point issues
    mutate(
      targeted_id = as.factor(targeted_id),
      game_id = as.factor(game_id),
      targeted_position = factor(targeted_position),
      air_time_scaled = scale(air_time)[, 1],
      d_throw_scaled = scale(d_throw)[, 1],
      pass_length_scaled = scale(pass_length)[, 1],
      defenders_in_the_box_scaled = scale(defenders_in_the_box)[, 1]
    )

  #Fit Model
  mem_model <- fit_mixed_effects_model(df_model)

  if (lme4::isSingular(mem_model)) {
    message("Warning: mixed-effects model fit is singular.")
  }

  print(summary(mem_model))

  #Model validation metrics
  y_obs <- df_model$BFD
  y_hat <- fitted(mem_model)
  resid <- y_obs - y_hat

  rmse <- sqrt(mean(resid^2, na.rm = TRUE))
  mae <- mean(abs(resid), na.rm = TRUE)
  r2 <- 1 - var(resid, na.rm = TRUE) / var(y_obs, na.rm = TRUE)

  mem_metrics <- tibble(
    metric = c("RMSE", "MAE", "Pseudo_R2"),
    value  = c(rmse, mae, r2)
  )
  print(mem_metrics)

  diag_df <- tibble(
    BFD = y_obs,
    fitted = y_hat,
    resid = resid
  )

  FIG_DIR <- get_fig_dir()

  p_fit <- ggplot(diag_df, aes(x = fitted, y = BFD)) +
    geom_point(alpha = 0.3, color = "#0072B2") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    theme_minimal() +
    labs(
      title = "Mixed-Effects Model: Fitted vs Observed BFD",
      x = "Fitted BFD",
      y = "Observed BFD"
    )

  ggsave(
    filename = file.path(FIG_DIR, "mixed_effects_fitted_vs_observed.png"),
    plot = p_fit,
    width = 8, height = 5, dpi = 300
  )

  p_resid <- ggplot(diag_df, aes(x = resid)) +
    geom_histogram(bins = 40, fill = "#D55E00", color = "white", alpha = 0.8) +
    theme_minimal() +
    labs(
      title = "Mixed-Effects Model Residuals (BFD)",
      x = "Residual",
      y = "Count"
    )

  ggsave(
    filename = file.path(FIG_DIR, "mixed_effects_residuals_hist.png"),
    plot = p_resid,
    width = 8, height = 5, dpi = 300
  )

  rankings <- extract_receiver_rankings(mem_model)

  target_counts <- df_model |>
    group_by(targeted_id) |>
    summarise(
      n_targets = n(),
      .groups = "drop"
    ) |>
    mutate(targeted_id = as.character(targeted_id))

  meta_map <- df_filtered |>
    distinct(targeted_id, targeted_name, targeted_position) |>
    mutate(targeted_id = as.character(targeted_id))

  rankings_full <- rankings |>
    left_join(meta_map, by = c("nfl_id" = "targeted_id")) |>
    left_join(target_counts, by = c("nfl_id" = "targeted_id")) |>
    relocate(targeted_name, .before = nfl_id) |>
    relocate(targeted_position, .after = targeted_name)

  rankings_qualified <- rankings_full |>
    filter(n_targets >= 30) |>
    arrange(desc(BFD_over_expected))

  print(head(rankings_qualified, 10))

  bayes_model <- fit_bayesian_BFD_model(df_model)
  bayes_rankings <- extract_bayesian_receiver_rankings(bayes_model)

  if (!is.null(bayes_model) && !is.null(bayes_rankings)) {
    bayes_rankings_full <- bayes_rankings |>
      left_join(meta_map, by = c("nfl_id" = "targeted_id")) |>
      left_join(target_counts, by = c("nfl_id" = "targeted_id")) |>
      relocate(targeted_name, .before = nfl_id) |>
      relocate(targeted_position, .after = targeted_name)

    bayes_rankings_qualified <- bayes_rankings_full |>
      filter(n_targets >= 30) |>
      arrange(desc(BFD_over_expected_mean))

    print(head(bayes_rankings_qualified, 10))

    saveRDS(bayes_model, file.path(PROC_DIR, "mixed_effects_model_bayes.rds"))
    write_csv(bayes_rankings_qualified, file.path(PROC_DIR, "receiver_rankings_bayes.csv"))
  } else {
    message("Bayesian BFD model not fit; skipping Bayesian rankings export.")
  }

  saveRDS(mem_model, file.path(PROC_DIR, "mixed_effects_model.rds"))
  write_csv(rankings_qualified, file.path(PROC_DIR, "receiver_rankings.csv"))
  write_csv(mem_metrics, file.path(PROC_DIR, "mixed_effects_metrics.csv"))

}
```

### Predictive Modeling of Final Separation (XGBoost)

While the mixed‑effects model attributes skill to receivers, we also ask a complementary question: **given what we know at the throw, how much separation should we expect at the catch?** To answer this, we fit a gradient‑boosted tree model (XGBoost) to predict $d_{catch}$ using only pre‑throw or contemporaneous features, including:

- Initial Differential $d_{throw}$
- Air time
- Play context (down, distance, field position)
- Aggregated route/coverage indicators and defensive structure variables

We train the model on a subset of plays and hold out a test set to evaluate performance. Our primary metric is **Root Mean Squared Error (RMSE)** in yards, supplemented by visual inspection of predicted vs. observed separation and a feature importance analysis.

Unlike the mixed‑effects model, which is built around interpretability and receiver random effects, XGBoost is optimized for predictive accuracy and can capture **non‑linear interactions** between features (e.g., how air time interacts with initial differential differently on certain route types).

```{r}
#| label: code-xgboost
#| eval: false
# Exact code used to train the XGBoost model for final separation.

# 07_ml_models.R

library(tidyverse)
set.seed(123)
if (!requireNamespace("xgboost", quietly = TRUE) ||
  !requireNamespace("caret", quietly = TRUE)) {
  stop("Packages 'xgboost' and 'caret' are required for 07_ml_models.R. Please install them.")
}

prepare_ml_data <- function(analysis_df) {

  desired_cols <- c(
    "d_catch", # target
    "d_throw",
    "air_time",
    "pass_length",
    "defenders_in_the_box",
    "expected_points",
    "expected_points_added",
    "yards_gained",
    "offense_formation",
    "receiver_alignment",
    "route_of_targeted_receiver",
    "team_coverage_man_zone",
    "team_coverage_type",
    "pass_location_type",
    "dropback_type"
  )

  available <- intersect(desired_cols, names(analysis_df))

  ml_df <- analysis_df |>
    select(all_of(available)) |>
    # Ensure target is present
    filter(!is.na(d_catch), !is.na(d_throw), !is.na(air_time)) |>
    # Handle categorical predictors as factors with explicit 'Unknown' level
    mutate(
      across(
        where(is.character),
        ~ factor(replace_na(.x, "Unknown"))
      )
    )

  ml_df
}

train_xgboost <- function(ml_df) {
  train_index <- caret::createDataPartition(ml_df$d_catch, p = 0.8, list = FALSE)
  train_data <- ml_df[train_index, ]
  test_data <- ml_df[-train_index, ]

  train_matrix <- model.matrix(d_catch ~ . - 1, data = train_data)
  test_matrix <- model.matrix(d_catch ~ . - 1, data = test_data)

  dtrain <- xgboost::xgb.DMatrix(
    data = train_matrix,
    label = train_data$d_catch
  )

  dtest <- xgboost::xgb.DMatrix(
    data = test_matrix,
    label = test_data$d_catch
  )

  params <- list(
    objective = "reg:squarederror",
    eta = 0.1,
    max_depth = 6,
    subsample = 0.8,
    colsample_bytree = 0.8
  )

  model <- xgboost::xgb.train(
    params = params,
    data = dtrain,
    nrounds = 100,
    watchlist = list(train = dtrain, test = dtest),
    print_every_n = 10,
    early_stopping_rounds = 10
  )

  importance <- xgboost::xgb.importance(model = model)
  importance_plot <- xgboost::xgb.plot.importance(importance_matrix = importance)

  pred_train <- predict(model, dtrain)
  pred_test <- predict(model, dtest)

  obs_train <- train_data$d_catch
  obs_test <- test_data$d_catch

  rmse_train <- sqrt(mean((obs_train - pred_train)^2, na.rm = TRUE))
  rmse_test <- sqrt(mean((obs_test - pred_test)^2, na.rm = TRUE))

  mae_train <- mean(abs(obs_train - pred_train), na.rm = TRUE)
  mae_test <- mean(abs(obs_test - pred_test), na.rm = TRUE)

  r2_train <- 1 - var(obs_train - pred_train, na.rm = TRUE) / var(obs_train, na.rm = TRUE)
  r2_test <- 1 - var(obs_test - pred_test, na.rm = TRUE) / var(obs_test, na.rm = TRUE)

  metrics <- tibble(
    split  = c("train", "test"),
    RMSE   = c(rmse_train, rmse_test),
    MAE    = c(mae_train, mae_test),
    R2     = c(r2_train, r2_test)
  )
  print(metrics)

  list(
    model = model,
    test_data = test_data,
    importance = importance,
    importance_plot = importance_plot,
    metrics = metrics,
    test_diag = tibble(
      obs  = obs_test,
      pred = pred_test
    )
  )
}


if (sys.nframe() == 0) {
  if (dir.exists("processed")) {
    PROC_DIR <- "processed"
  } else if (dir.exists("../processed")) {
    PROC_DIR <- "../processed"
  } else {
    stop("Could not find 'processed' directory.")
  }

  analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
  if (!file.exists(analysis_path)) stop("analysis_full.rds not found.")

  df <- readRDS(analysis_path)
  ml_data <- prepare_ml_data(df)

  res <- train_xgboost(ml_data)

  if (!dir.exists("figures")) dir.create("figures")
  if (inherits(res$importance_plot, "ggplot")) {
    importance_fig <- res$importance_plot + ggplot2::theme_minimal(base_size = 14)
    ggplot2::ggsave(
      filename = file.path("figures", "feature_importance.png"),
      plot = importance_fig,
      width = 8,
      height = 5,
      dpi = 300
    )
  } else {
    message("Feature importance plot not available; skipping feature_importance.png.")
  }

  p_pred <- ggplot(res$test_diag, aes(x = pred, y = obs)) +
    geom_point(alpha = 0.3, color = "#009E73") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    theme_minimal() +
    labs(
      title = "XGBoost: Predicted vs Observed d_catch (Test Set)",
      x = "Predicted d_catch",
      y = "Observed d_catch"
    )

  ggplot2::ggsave(
    filename = file.path("figures", "xgboost_pred_vs_observed.png"),
    plot = p_pred,
    width = 8,
    height = 5,
    dpi = 300
  )

  saveRDS(res$model, file.path(PROC_DIR, "xgboost_model.rds"))
  write_csv(res$metrics, file.path(PROC_DIR, "xgboost_metrics.csv"))
}
```

```{r}
#| label: code-visualizations
#| eval: false
# Exact code used to generate figures for BFD, routes, coverage, and Bayesian intervals.

# 04_visualizations.R
library(tidyverse)
library(ggplot2)

plot_BFD_distribution <- function(data) {
  ggplot(data, aes(x = BFD)) +
    geom_histogram(binwidth = 0.5, fill = "#0072B2", color = "white", alpha = 0.8) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
    theme_minimal() +
    labs(
      title = "Distribution of Ball-Flight Differential added (BFD)",
      subtitle = "Full Data Analysis",
      x = "BFD (Yards Gained/Lost)",
      y = "Number of Plays",
      caption = "Positive BFD = Separation Gained, Negative BFD = Separation Lost"
    )
}

plot_BFD_vs_airtime <- function(data) {
  ggplot(data, aes(x = air_time, y = BFD)) +
    geom_point(alpha = 0.5, color = "#D55E00") +
    geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
    theme_minimal() +
    labs(
      title = "BFD vs. Air Time",
      subtitle = "Longer throws give defenders more time to close in",
      x = "Air Time (seconds)",
      y = "BFD (Yards)"
    )
}

plot_BFD_vs_throw_separation <- function(data) {
  ggplot(data, aes(x = d_throw, y = BFD)) +
    geom_point(alpha = 0.5, color = "#009E73") +
    geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
    theme_minimal() +
    labs(
      title = "BFD vs. Initial Differential at Throw",
      subtitle = "Regression to the mean: Open receivers tend to lose separation",
      x = "Separation at Throw (Yards)",
      y = "BFD (Yards)"
    )
}

plot_BFD_by_route <- function(data, min_plays = 50) {
  data |>
    filter(!is.na(route_of_targeted_receiver)) |>
    group_by(route_of_targeted_receiver) |>
    summarise(
      n = n(),
      avg_BFD = mean(BFD, na.rm = TRUE)
    ) |>
    filter(n >= min_plays) |>
    arrange(desc(avg_BFD)) |>
    mutate(route_of_targeted_receiver = fct_reorder(route_of_targeted_receiver, avg_BFD)) |>
    ggplot(aes(x = route_of_targeted_receiver, y = avg_BFD)) +
    geom_col(fill = "#0072B2") +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Average BFD by Route Type",
      subtitle = paste("Routes with at least", min_plays, "plays"),
      x = "Route of Targeted Receiver",
      y = "Average BFD (Yards)"
    )
}

# BFD by coverage type (man/zone)
plot_BFD_by_coverage <- function(data, min_plays = 50) {
  data |>
    filter(!is.na(team_coverage_man_zone)) |>
    group_by(team_coverage_man_zone) |>
    summarise(
      n = n(),
      avg_BFD = mean(BFD, na.rm = TRUE)
    ) |>
    filter(n >= min_plays) |>
    ggplot(aes(x = fct_reorder(team_coverage_man_zone, avg_BFD), y = avg_BFD)) +
    geom_col(fill = "#D55E00") +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Average BFD by Coverage Family",
      subtitle = paste("Man vs Zone concepts (at least", min_plays, "plays)"),
      x = "Coverage (Man/Zone)",
      y = "Average BFD (Yards)"
    )
}

plot_bayesian_BFD_intervals <- function(rankings_bayes, top_n = 15) {
  if (!"BFD_over_expected_mean" %in% names(rankings_bayes)) {
    return(NULL)
  }

  if ("targeted_name" %in% names(rankings_bayes)) {
    rankings_bayes <- rankings_bayes |>
      mutate(label = targeted_name)
  } else {
    rankings_bayes <- rankings_bayes |>
      mutate(label = as.character(nfl_id))
  }

  rankings_bayes |>
    filter(!is.na(BFD_over_expected_mean)) |>
    slice_max(BFD_over_expected_mean, n = top_n, with_ties = FALSE) |>
    mutate(label = fct_reorder(label, BFD_over_expected_mean)) |>
    ggplot(aes(x = label, y = BFD_over_expected_mean)) +
    geom_point(color = "#0072B2") +
    geom_errorbar(
      aes(ymin = BFD_over_expected_lower, ymax = BFD_over_expected_upper),
      width = 0
    ) +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Top Receivers by BFD Over Expected (Bayesian)",
      subtitle = "Posterior mean and 95% credible intervals",
      x = "Receiver",
      y = "BFD Over Expected (Yards)"
    )
}

plot_bayesian_markov_intervals <- function(lift_bayes, top_n = 15) {
  if (!"player_rate_mean" %in% names(lift_bayes)) {
    return(NULL)
  }

  if ("player_rate_lower.2.5%" %in% names(lift_bayes) &&
    !"player_rate_lower" %in% names(lift_bayes)) {
    lift_bayes <- lift_bayes |>
      dplyr::rename(
        player_rate_lower = `player_rate_lower.2.5%`,
        player_rate_upper = `player_rate_upper.97.5%`
      )
  }

  if ("targeted_name" %in% names(lift_bayes)) {
    lift_bayes <- lift_bayes |>
      mutate(label = targeted_name)
  } else {
    lift_bayes <- lift_bayes |>
      mutate(label = as.character(targeted_id))
  }

  lift_bayes |>
    filter(!is.na(player_rate_mean)) |>
    slice_max(player_rate_mean, n = top_n, with_ties = FALSE) |>
    mutate(
      label = fct_reorder(label, player_rate_mean),
      player_rate_pct = player_rate_mean
    ) |>
    ggplot(aes(x = label, y = player_rate_pct)) +
    geom_point(color = "#D55E00") +
    geom_errorbar(
      aes(
        ymin = player_rate_lower,
        ymax = player_rate_upper
      ),
      width = 0
    ) +
    coord_flip() +
    theme_minimal() +
    labs(
      title = "Top Receivers by Break-Open Rate (Bayesian Markov Lift)",
      subtitle = "Per-frame break-open probability with 95% credible intervals",
      x = "Receiver",
      y = "Break-Open Probability (%)"
    )
}

if (sys.nframe() == 0) {
  if (file.exists("src/utils_paths.R")) {
    source("src/utils_paths.R")
  } else if (file.exists("utils_paths.R")) {
    source("utils_paths.R")
  } else {
    stop("Could not find 'utils_paths.R'.")
  }

  PROC_DIR <- get_proc_dir()

  analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
  if (!file.exists(analysis_path)) {
    analysis_path_w1 <- file.path(PROC_DIR, "analysis_w01.rds")
    if (file.exists(analysis_path_w1)) {
      warning("analysis_full.rds not found, using analysis_w01.rds")
      analysis_path <- analysis_path_w1
    } else {
      stop(paste(analysis_path, "not found. Run 02_compute_BFD.R first."))
    }
  }

  df <- readRDS(analysis_path)

  if (all(c("pass_length", "targeted_position") %in% names(df))) {
    message("Filtering visuals to WR/TE forward-pass targets for consistency with modeling...")
    df <- df |>
      filter(
        !is.na(pass_length),
        pass_length > 0,
        targeted_position %in% c("WR", "TE")
      )
  }

  missing_BFD <- sum(is.na(df$BFD))
  if (missing_BFD > 0) {
    message(sprintf("Note: Removing %d rows where BFD could not be calculated (likely due to missing defender tracking data in output).", missing_BFD))
    df <- df[!is.na(df$BFD), ]
  }

  FIG_DIR <- get_fig_dir()

  p1 <- plot_BFD_distribution(df)
  ggsave(file.path(FIG_DIR, "BFD_distribution.png"), p1, width = 8, height = 5)

  p2 <- plot_BFD_vs_airtime(df)
  ggsave(file.path(FIG_DIR, "BFD_vs_airtime.png"), p2, width = 8, height = 5)

  p3 <- plot_BFD_vs_throw_separation(df)
  ggsave(file.path(FIG_DIR, "BFD_vs_dthrow.png"), p3, width = 8, height = 5)

  # New contextual plots if supplementary data is present
  if ("route_of_targeted_receiver" %in% names(df)) {
    p4 <- plot_BFD_by_route(df)
    ggsave(file.path(FIG_DIR, "BFD_by_route.png"), p4, width = 8, height = 6)
  }

  if ("team_coverage_man_zone" %in% names(df)) {
    p5 <- plot_BFD_by_coverage(df)
    ggsave(file.path(FIG_DIR, "BFD_by_coverage.png"), p5, width = 8, height = 6)
  }
  bayes_BFD_path <- file.path(PROC_DIR, "receiver_rankings_bayes.csv")
  if (file.exists(bayes_BFD_path)) {
    rankings_bayes <- read_csv(bayes_BFD_path, show_col_types = FALSE)
    p6 <- plot_bayesian_BFD_intervals(rankings_bayes, top_n = 15)
    if (!is.null(p6)) {
      ggsave(file.path(FIG_DIR, "receiver_BFD_bayes_intervals.png"), p6, width = 8, height = 6)
    }
  }

  bayes_markov_path <- file.path(PROC_DIR, "markov_lift_rankings_bayes.csv")
  if (file.exists(bayes_markov_path)) {
    lift_bayes <- read_csv(bayes_markov_path, show_col_types = FALSE)
    p7 <- plot_bayesian_markov_intervals(lift_bayes, top_n = 15)
    if (!is.null(p7)) {
      ggsave(file.path(FIG_DIR, "markov_lift_bayes_intervals.png"), p7, width = 8, height = 6)
    }
  }
}
```

### Reproducible Pipeline

All intermediate data products and model outputs flow through a scripted R pipeline. For reproducibility, the main steps are:

```{r}
#| label: full-pipeline
#| eval: false

# 1) Feature engineering and separation trajectories for each week
source("src/01_engineer_features.R")

# 2) Compute BFD and join supplementary play-level context
source("src/02_compute_BFD.R")

# 3) Fit mixed-effects model and write receiver rankings + metrics
source("src/03_models.R")

# 4) Compute Markov transition matrix and Markov Lift rankings
source("src/06_markov_separation.R")

# 5) Train XGBoost model and export feature importance + validation metrics
source("src/07_ml_models.R")
```

```{r}
#| label: code-utils-paths
#| eval: false
# Helper used throughout the pipeline to resolve processed/figures directories.

## utils_paths.R

get_proc_dir <- function() {
    if (dir.exists("processed")) {
        return("processed")
    }
    if (dir.exists("../processed")) {
        return("../processed")
    }
    stop("Could not find 'processed' directory.")
}

get_fig_dir <- function() {
    if (dir.exists("../figures")) {
        return("../figures")
    }
    if (dir.exists("figures")) {
        return("figures")
    }
    dir.create("figures", showWarnings = FALSE)
    "figures"
}
```

## Results

### Separation Dynamics (BFD)

```{r}
#| label: code-bfd-distribution
#| eval: false
# Code used to generate ../figures/BFD_distribution.png
#
# This code mirrors src/04_visualizations.R.

if (file.exists("src/utils_paths.R")) {
  source("src/utils_paths.R")
} else if (file.exists("utils_paths.R")) {
  source("utils_paths.R")
} else {
  stop("Could not find 'utils_paths.R'.")
}

PROC_DIR <- get_proc_dir()

analysis_path <- file.path(PROC_DIR, "analysis_full.rds")
if (!file.exists(analysis_path)) {
  analysis_path_w1 <- file.path(PROC_DIR, "analysis_w01.rds")
  if (file.exists(analysis_path_w1)) {
    warning("analysis_full.rds not found, using analysis_w01.rds")
    analysis_path <- analysis_path_w1
  } else {
    stop(paste(analysis_path, "not found. Run 02_compute_BFD.R first."))
  }
}

df <- readRDS(analysis_path)

if (all(c("pass_length", "targeted_position") %in% names(df))) {
  message("Filtering visuals to WR/TE forward-pass targets for consistency with modeling...")
  df <- df |>
    dplyr::filter(
      !is.na(pass_length),
      pass_length > 0,
      targeted_position %in% c("WR", "TE")
    )
}

missing_BFD <- sum(is.na(df$BFD))
if (missing_BFD > 0) {
  message(sprintf(
    "Note: Removing %d rows where BFD could not be calculated (likely due to missing defender tracking data in output).",
    missing_BFD
  ))
  df <- df[!is.na(df$BFD), ]
}

FIG_DIR <- get_fig_dir()

p1 <- plot_BFD_distribution(df)
ggsave(file.path(FIG_DIR, "BFD_distribution.png"), p1, width = 8, height = 5)
```

![Distribution of BFD](../figures/BFD_distribution.png)

Across the 14,108 passing plays we studied, defenders usually start to close in on receivers once the ball is in the air, so the defenders gain yards with respect to the receiver when the ball is thrown, and the catch is complete/incomplete. The average Ball-Flight Differential (BFD) is -.82 yards, and the distribution is centered to the left of zero with a left skew (long left tail). This means that the deeper throws have defenders closing space toward the receiver who is stationed further down the field. Whereas a right-skewed tail means that the receivers are gaining yards against the defender. 

The negative mean baseline means that receivers gain positive yards against the defender; it means they are skilled. Most plays stay around 0, meaning that the routes the receiver and defender hold about the same cushion around the ball in the air. The snaps show little to no separation loss, which aligns with the defenders' tighter coverage on deeper routes, allowing them to close space. A smaller right tail means that receivers create separation in the air with route and speed. 


### Drivers of Ball-Flight Differential 

The mixed effects model shows how initial differential, air time, and context are all relevant to contributing to the BFD. 

```{r}
#| label: code-bfd-vs-airtime
#| eval: false
# Code used to generate ../figures/BFD_vs_airtime.png
#
# Assumes df and FIG_DIR have been created as in the code-bfd-distribution chunk above.

p2 <- plot_BFD_vs_airtime(df)
ggsave(file.path(FIG_DIR, "BFD_vs_airtime.png"), p2, width = 8, height = 5)
```

![BFD vs Air Time](../figures/BFD_vs_airtime.png)
Air Time shows that the longer the throw, the more separation is lost. The coefficient is approximately -0.09 (how when it is a positive linear line)and statistically significant with a p-value < .01. This means that adding half a second to a throw flight time costs about .045 yards of separation on average. Thus, the deeper balls give defenders more time to recover.

```{r}
#| label: code-bfd-vs-dthrow
#| eval: false
# Code used to generate ../figures/BFD_vs_dthrow.png
#
# Assumes df and FIG_DIR have been created as in the code-bfd-distribution chunk above.

p3 <- plot_BFD_vs_throw_separation(df)
ggsave(file.path(FIG_DIR, "BFD_vs_dthrow.png"), p3, width = 8, height = 5)
```

![BFD vs Initial Differential](../figures/BFD_vs_dthrow.png)

Initial Differential shows that extreme situations move back toward normal by the time the ball arrives, as the coefficient is -0.39 which is statistically significant with a p-value < .01. Routes open at the throw basically, extreme situations tend to move back toward “normal” by the time the ball arrives. For every extra yard of openness when the ball is thrown, the receiver loses about 0.39 yards of advantage by the time the ball throw is completed.

![Mixed-Effects Fitted vs Observed](../figures/mixed_effects_fitted_vs_observed.png)

The fitted vs observed are about centered and symmetric for a normal distribution. This can be further strengthened by the histogram below.

![Mixed-Effects Residuals](../figures/mixed_effects_residuals_hist.png)

The air time, initial differential, and covariates explain a meaningful part of the variation in the Ball-Flight Differential. Still, the variation can be accounted for by other relevant factors like the receiver, quarterback, ball location, etc.


### Markov Chain 

![Markov Transition Matrix](../figures/markov_transitions.png)

**Top Receivers by Markov Lift**:

```{r}
#| label: load-markov-rankings
library(tidyverse)
library(knitr)

lift_path <- "../processed/markov_lift_rankings.csv"
lift_bayes_path <- "../processed/markov_lift_rankings_bayes.csv"

if (file.exists(lift_path)) {
  lift <- read_csv(lift_path)

  top_lift <- lift |>
    head(5) |>
    mutate(
      player_rate = paste0(round(player_rate * 100, 1), "%"),
      markov_lift = paste0("+", round(markov_lift * 100, 1), "%")
    )

  if ("targeted_name" %in% names(top_lift)) {
    top_lift |>
      select(targeted_id, targeted_name, player_rate, markov_lift) |>
      kable(col.names = c("ID", "Player", "Success Rate", "Markov Lift"))
  } else if ("displayName" %in% names(top_lift)) {
    top_lift |>
      select(targeted_id, displayName, player_rate, markov_lift) |>
      kable(col.names = c("ID", "Player", "Success Rate", "Markov Lift"))
  } else {
    top_lift |>
      select(targeted_id, player_rate, markov_lift) |>
      kable(col.names = c("ID", "Success Rate", "Markov Lift"))
  }
}
```

```{r}

if (file.exists(lift_bayes_path)) {
  lift_bayes <- read_csv(lift_bayes_path) |>
    rename(
      player_rate_lower = `player_rate_lower.2.5%`,
      player_rate_upper = `player_rate_upper.97.5%`
    )

  top_lift_bayes <- lift_bayes |>
    head(5) |>
    mutate(
      player_rate = paste0(round(player_rate_mean * 100, 1), "%"),
      cr_interval = paste0(
        "[", round(player_rate_lower * 100, 1), "%, ",
        round(player_rate_upper * 100, 1), "%]"
      )
    )

  if ("targeted_name" %in% names(top_lift_bayes)) {
    top_lift_bayes |>
      select(targeted_id, targeted_name, player_rate, cr_interval) |>
      kable(col.names = c("ID", "Player", "Break-Open Rate", "95% CrI"))
  } else if ("displayName" %in% names(top_lift_bayes)) {
    top_lift_bayes |>
      select(targeted_id, displayName, player_rate, cr_interval) |>
      kable(col.names = c("ID", "Player", "Break-Open Rate", "95% CrI"))
  } else {
    top_lift_bayes |>
      select(targeted_id, player_rate, cr_interval) |>
      kable(col.names = c("ID", "Break-Open Rate", "95% CrI"))
  }
}
```

This matrix shows how various states remain similar when moving onto the next frame, like for S3 Wide Open versus S2 Open. 

We use this to find receivers who are more skilled at breaking open during mid-route. The Markov Lift shows the difference between the league average and the player’s break-open probability. Thus, we can interpret big, positive Markov Lift numbers as the ability to make tight coverage into open windows more often than we would expect across many games. 

The receivers at the top of this table show that they get open more often on average than NFL players usually do. A 5% markov lift signifies a player who finds space 5% more on average than the league average. Thus, this player circumvents the defender and wins leverage, which helps them show up open on the quarterback's perspective more than others. Even after accounting for randomness, limited snaps, route variation, etc., the receivers with high lifts are still above average. +0.19 percentage points above the league baseline average (1.49% per frame), i.e., Olave breaks open slightly more often than an average receiver in similar situations.

Thus, receivers who run a lot of routes and typically create space have smaller intervals, so we are more confident in their high openness average. Then, the receivers with fewer routes or fewer roles can look fantastic, but their intervals are wide, which means more uncertainty about their performance being above average.

```{r}
#| label: code-markov-lift-bayes-intervals
#| eval: false
# Code used to generate ../figures/markov_lift_bayes_intervals.png
#
# Assumes get_proc_dir() and get_fig_dir() are available from utils_paths.R as shown earlier.

PROC_DIR <- get_proc_dir()
FIG_DIR <- get_fig_dir()

bayes_markov_path <- file.path(PROC_DIR, "markov_lift_rankings_bayes.csv")
if (file.exists(bayes_markov_path)) {
  lift_bayes <- readr::read_csv(bayes_markov_path, show_col_types = FALSE)
  p7 <- plot_bayesian_markov_intervals(lift_bayes, top_n = 15)
  if (!is.null(p7)) {
    ggsave(file.path(FIG_DIR, "markov_lift_bayes_intervals.png"), p7, width = 8, height = 6)
  }
}
```

![Bayesian Markov Lift Intervals](../figures/markov_lift_bayes_intervals.png)


### XGBoost: Predictive Model

Our XGBoost model predicts final space differential between receiver and defender using the information provided prior to the ball being in flight. 

On the held‑out test set, the model attains an RMSE of **1.79 yards**, meaning that predictions are typically within about two yards of the observed separation. This predictive metric helps:

- Distinguish between receivers who make themselves wide‑open versus tightly positioned receivers.
- Find circumstances which typically have open throws, like routes, coverage, etc.

Overall, the model's scores to determine the signficance of various features shows that Initial Differential is most predictive, then Air Time follows suit. While there are other features that help explain and predict the results, they are not as impactful to the model. Below, we can see the predicted versus observed plot to show how the points have moderate variance:

![XGBoost Predicted vs Observed](../figures/xgboost_pred_vs_observed.png)

These inputs provide the most accuracy in our predictions:

![XGBoost Feature Importance](../figures/feature_importance.png)

This shows noisy outcomes with high-variance where the variance is not fully captured in our model features, which can include ball placement, contact between players on the field, etc.


### Top Receivers (Ball-Flight Differential Over Expected)

```{r}
#| label: load-rankings
rankings_path <- "../processed/receiver_rankings.csv"
if(file.exists(rankings_path)) {
  rankings <- read_csv(rankings_path)

  top_rank <- rankings |>
    head(10)

  if ("targeted_name" %in% names(top_rank) && "targeted_position" %in% names(top_rank)) {
    top_rank |>
      select(nfl_id, targeted_name, targeted_position, BFD_over_expected) |>
      kable(col.names = c("ID", "Player", "Pos", "BFD Over Expected"), digits = 3)
  } else if ("displayName" %in% names(top_rank) && "targeted_position" %in% names(top_rank)) {
    top_rank |>
      select(nfl_id, displayName, targeted_position, BFD_over_expected) |>
      kable(col.names = c("ID", "Player", "Pos", "BFD Over Expected"), digits = 3)
  } else if ("targeted_name" %in% names(top_rank)) {
    top_rank |>
      select(nfl_id, targeted_name, BFD_over_expected) |>
      kable(col.names = c("ID", "Player", "BFD Over Expected"), digits = 3)
  } else if ("displayName" %in% names(top_rank)) {
    top_rank |>
      select(nfl_id, displayName, BFD_over_expected) |>
      kable(col.names = c("ID", "Player", "BFD Over Expected"), digits = 3)
  } else {
    top_rank |>
      select(nfl_id, BFD_over_expected) |>
      kable(col.names = c("ID", "BFD Over Expected"), digits = 3)
  }
}
```

```{r}
#| label: load-bayesian-rankings
rankings_bayes_path <- "../processed/receiver_rankings_bayes.csv"
if (file.exists(rankings_bayes_path)) {
  rankings_bayes <- read_csv(rankings_bayes_path)

  top_rank_bayes <- rankings_bayes |>
    head(10) |>
    mutate(
      BFD_mean = round(BFD_over_expected_mean, 3),
      BFD_cri = paste0(
        "[", round(BFD_over_expected_lower, 3), ", ",
        round(BFD_over_expected_upper, 3), "]"
      )
    )

  if ("targeted_name" %in% names(top_rank_bayes)) {
    top_rank_bayes |>
      select(nfl_id, targeted_name, BFD_mean, BFD_cri) |>
      kable(col.names = c("ID", "Player", "BFD OE (Mean)", "95% CrI"))
  } else if ("displayName" %in% names(top_rank_bayes)) {
    top_rank_bayes |>
      select(nfl_id, displayName, BFD_mean, BFD_cri) |>
      kable(col.names = c("ID", "Player", "BFD OE (Mean)", "95% CrI"))
  } else {
    top_rank_bayes |>
      select(nfl_id, BFD_mean, BFD_cri) |>
      kable(col.names = c("ID", "BFD OE (Mean)", "95% CrI"))
  }
}
```

The wider confidence intervals (high variance) around the receiver’s values show that the players are not consistent, as they are open for some plays and disappear on others. On the other hand, the smaller intervals show players who are consistently reliable to gain separation in the air. 

The receivers with large positive BFD Over Expected values meant that they consistently beat the model. After accounting for the throw difficulty with air time, initial differential, etc., they still end up more open at the catch than other similar players in similar situations by adjusting to the ball, having great tracking skills, etc. 

Receivers with negative values rely on the timing and scheme, while somewhat struggling to keep leverage when the ball is released. They may be open at first, but do not sustain this openness throughout the throw in the air. These leaderboards are restricted to wide receivers and tight ends with at least 30 forward‑pass targets in the 2023 regular season so we have enough data to use for the receiver rankings. 

For example, Chris Olave has an BFD Over Expected of about 0.15, with a narrower CI of -0.07 to 0.38. This means Olave is consistent by adding about a quarter yard of separation during the throw (after already accounting for route, defender, air in time, etc.). The narrower CI says that this separation is not due to noise of lucky plays, but rather that Olave is consistent. On the other hand, Kalif Raymond has an BFD Over Expected of about 0.24 and a wider CI of -0.03 to 0.58. While Raymond adds about half a yard of separation during the throw, which is better ball flight differential than Olave, we are not very confident that this is how he truly, consistently plays due to the wide CI. Thus, his BFD varies due to scheme, play, routes, mismatches of players, etc. There may be times when Raymond separates, versus times when he is not open at all. Overall, Olave shows a smaller, but more reliable pattern of separation, to frequently breaking open.

```{r}
#| label: code-bfd-bayes-intervals
#| eval: false
# Code used to generate ../figures/receiver_BFD_bayes_intervals.png
#
# Assumes get_proc_dir() and get_fig_dir() are available from utils_paths.R as shown earlier.

PROC_DIR <- get_proc_dir()
FIG_DIR <- get_fig_dir()

bayes_BFD_path <- file.path(PROC_DIR, "receiver_rankings_bayes.csv")
if (file.exists(bayes_BFD_path)) {
  rankings_bayes <- readr::read_csv(bayes_BFD_path, show_col_types = FALSE)
  p6 <- plot_bayesian_BFD_intervals(rankings_bayes, top_n = 15)
  if (!is.null(p6)) {
    ggsave(file.path(FIG_DIR, "receiver_BFD_bayes_intervals.png"), p6, width = 8, height = 6)
  }
}
```

![Bayesian BFD Over Expected Intervals](../figures/receiver_BFD_bayes_intervals.png)


## Improvements

To improve our BFD metric, we would want to **filter by C in the pass_result** column, so we could see the effect on BFD dependent on if the throw was complete, incomplete, or intercepted. We also wanted to avoid selection bias by not only filtering towards good plays. Overall, we not only want to see if they have sticky hands, but how typical it is for the receiver to distance themselves from the defenders despite the outcome. We could also include the **routes with fixed effects (dig, go, etc.)** and create interaction terms to know which routes relate to more or less BFD skill. Another improvement could be to **weight the BFD metrics by the value** of their skill in the field; specifically, the catch probability and expected points added could help weight how much the BFD affects the value on the field. 
